{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets pennylane\nfrom datasets import load_dataset\n\nds = load_dataset(\"mattymchen/mr\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T04:08:17.974597Z","iopub.execute_input":"2026-02-16T04:08:17.974918Z","iopub.status.idle":"2026-02-16T04:08:33.788461Z","shell.execute_reply.started":"2026-02-16T04:08:17.974891Z","shell.execute_reply":"2026-02-16T04:08:33.787877Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nCollecting pennylane\n  Downloading pennylane-0.44.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.15.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.5)\nCollecting rustworkx>=0.14.0 (from pennylane)\n  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\nCollecting appdirs (from pennylane)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nCollecting autoray==0.8.2 (from pennylane)\n  Downloading autoray-0.8.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\nCollecting pennylane-lightning>=0.44 (from pennylane)\n  Downloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\nCollecting diastatic-malt (from pennylane)\n  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.1rc0)\nCollecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.44->pennylane)\n  Downloading scipy_openblas32-0.3.31.22.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.6.3)\nRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\nRequirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.1.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\nDownloading pennylane-0.44.0-py3-none-any.whl (5.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading autoray-0.8.2-py3-none-any.whl (935 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m935.6/935.6 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy_openblas32-0.3.31.22.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\nSuccessfully installed appdirs-1.4.4 autoray-0.8.2 diastatic-malt-2.15.2 pennylane-0.44.0 pennylane-lightning-0.44.0 rustworkx-0.17.1 scipy-openblas32-0.3.31.22.1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/688 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84778d920036451aac3faa95140b5e59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001-1ad570418120a67(â€¦):   0%|          | 0.00/884k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8bf027773348ecab2916810254f003"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10662 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93af30620cb640ab81c3f267f2f6daa5"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T16:01:20.073806Z","iopub.execute_input":"2026-02-14T16:01:20.074221Z","iopub.status.idle":"2026-02-14T16:01:20.078938Z","shell.execute_reply.started":"2026-02-14T16:01:20.074195Z","shell.execute_reply":"2026-02-14T16:01:20.078364Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 10662\n    })\n})"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# **DistilBERT**","metadata":{}},{"cell_type":"code","source":"!pip install pennylane\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport torch\nfrom sklearn.metrics import (\n    roc_curve, roc_auc_score, classification_report, confusion_matrix\n)\nfrom sklearn.preprocessing import label_binarize\nimport pennylane as qml\nfrom pennylane import numpy as pnp\nimport re\nimport warnings\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nwarnings.filterwarnings('ignore')\n# Label encoding for 'status' column\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AutoModel\nimport pennylane as qml\n# Convert data to PyTorch DataLoader format\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, roc_curve, auc\nfrom transformers import get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\nfrom sklearn.model_selection import ParameterSampler\nimport random\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport numpy as np\nimport torch\nfrom sklearn.preprocessing import label_binarize\nimport time\nimport random\nimport numpy as np\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom transformers import get_linear_schedule_with_warmup\nfrom transformers import AutoTokenizer, AutoModel\n\n# ---------------------------\n# Load MPQA Dataset\n# ---------------------------\nds = load_dataset(\"mattymchen/mr\")\n# Convert train split to pandas (MPQA already split)\ndf = ds[\"test\"].to_pandas()\n\nprint(df.head())\nprint(df.shape)\n\n# MPQA typically has columns: 'text' and 'label'\n# If column name is different, print df.columns to check.\n\n# ---------------------------\n# Basic Preprocessing\n# ---------------------------\n\ndef preprocess_text(text):\n    text = re.sub(r'\\s+', ' ', text)\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n    text = re.sub(r'@\\w+', '', text)\n    text = re.sub(r'#\\w+', '', text)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = text.lower()\n    return text\n\ndf['cleaned_text'] = df['text'].apply(preprocess_text)\n\n# ---------------------------\n# Remove Stopwords\n# ---------------------------\n\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\ndef clean_statement(statement):\n    statement = statement.lower()\n    statement = re.sub(r'[^\\w\\s]', '', statement)\n    statement = re.sub(r'\\d+', '', statement)\n    words = statement.split()\n    words = [word for word in words if word not in stop_words]\n    cleaned_statement = ' '.join(words)\n    return cleaned_statement\n\ndf['cleaned_text'] = df['cleaned_text'].apply(clean_statement)\n\nprint(df.head())\n\n# ---------------------------\n# Label Encoding\n# ---------------------------\n# MPQA labels are usually already numeric (0,1)\n# But we keep this step for safety\n\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['label'])\n\nprint(df['label'].value_counts())\n\n# ---------------------------\n# Balance Dataset\n# ---------------------------\n\nmajority_class = df['label'].value_counts().idxmax()\nminority_class = df['label'].value_counts().idxmin()\n\ndf_majority = df[df['label'] == majority_class]\ndf_minority = df[df['label'] == minority_class]\n\n# Downsample majority\ndf_majority_downsampled = df_majority.sample(len(df_minority), random_state=42)\n\n# Combine\ndf_balanced = pd.concat([df_majority_downsampled, df_minority])\n\n# Shuffle\ndf_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(\"Balanced Class Distribution:\")\nprint(df_balanced['label'].value_counts())\n\ndf_balanced.head()\n\n\n# Initialize the tokenizer and model from Hugging Face\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ntokens = tokenizer.batch_encode_plus(\n    df['cleaned_text'].tolist(),\n    max_length=128,\n    padding=\"max_length\",   # <-- updated\n    truncation=True,\n    return_tensors=\"pt\"\n)\n\n# Convert to tensors\ninput_ids = torch.tensor(tokens['input_ids'])\nattention_masks = torch.tensor(tokens['attention_mask'])\nlabels = torch.tensor(df['label'].values)\n\n# Split the data into training and validation sets\ntrain_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.2)\ntrain_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids, test_size=0.2)\n\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\nval_data = TensorDataset(val_inputs, val_masks, val_labels)\n\ntrain_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=32)\nval_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=32)\n\n# Create a quantum node (circuit)\ndev = qml.device(\"default.qubit\", wires=2)  # or 'default.qubit'\n\n@qml.qnode(dev)\n@qml.qnode(dev)\ndef quantum_circuit(weights, inputs):\n    qml.Hadamard(wires=0)\n    qml.Hadamard(wires=1)\n\n    qml.RX(inputs[0], wires=0)\n    qml.RY(inputs[1], wires=1)\n\n    qml.CNOT(wires=[0, 1])\n\n    qml.RZ(weights[0], wires=0)\n    qml.RZ(weights[1], wires=1)\n\n    return qml.expval(qml.PauliZ(0))\n\nclass QBiLSTM(nn.Module):\n    def __init__(self):\n        super(QBiLSTM, self).__init__()\n\n        self.bert = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n\n        # ğŸ” BiLSTM instead of LSTM\n        self.bilstm = nn.LSTM(\n            input_size=768,\n            hidden_size=128,\n            batch_first=True,\n            bidirectional=True\n        )\n\n        # 128 Ã— 2 because BiLSTM\n        self.fc = nn.Linear(256, 2)\n\n    def quantum_layer(self, inputs):\n        processed_features = []\n\n        for feature_vector in inputs:\n            features_for_quantum = feature_vector[:2]\n            q_out = quantum_circuit(\n                torch.randn(2, dtype=torch.float32),\n                features_for_quantum\n            )\n            processed_features.append(q_out)\n\n        return torch.stack(processed_features).unsqueeze(1)\n\n    def forward(self, input_ids, attention_mask):\n        bert_output = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n\n        # BiLSTM output\n        lstm_output, _ = self.bilstm(bert_output.last_hidden_state)\n\n        # Last timestep (batch, 256)\n        last_hidden = lstm_output[:, -1, :]\n\n        _ = self.quantum_layer(last_hidden)\n\n        # Classification\n        output = self.fc(last_hidden)\n        return output\n\n\nmodel = QBiLSTM()\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define hyperparameter search space\nparam_grid = {\n    'learning_rate': [1e-5, 2e-5, 3e-5, 5e-5],\n    'batch_size': [16, 32],\n    'epochs': [3, 5, 7]\n}\n\nnum_samples = 5  \nparam_list = list(ParameterSampler(param_grid, n_iter=num_samples, random_state=42))\n\nbest_model = None\nbest_val_accuracy = 0.0\nbest_params = None\n\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n# Loop through each random set of hyperparameters\nfor idx, params in enumerate(param_list):\n    print(f\"Testing configuration {idx + 1}: {params}\")\n\n    learning_rate = params['learning_rate']\n    batch_size = params['batch_size']\n    epochs = params['epochs']\n\n    # Define optimizer and scheduler\n    optimizer = AdamW(model.parameters(), lr=learning_rate)\n    total_steps = len(train_dataloader) * epochs\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n    for epoch in range(epochs):\n        start_time = time.time()\n        model.train()\n        total_train_loss = 0\n        total_train_accuracy = 0\n\n        for batch in train_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n\n            # Move tensors to the same device\n            b_input_ids = b_input_ids.to(device)\n            b_input_mask = b_input_mask.to(device)\n            b_labels = b_labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(b_input_ids, b_input_mask)\n            loss = nn.CrossEntropyLoss()(outputs, b_labels)\n            total_train_loss += loss.item()\n\n            logits = outputs.detach().cpu().numpy()\n            label_ids = b_labels.cpu().numpy()\n            total_train_accuracy += flat_accuracy(logits, label_ids)\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        avg_train_loss = total_train_loss / len(train_dataloader)\n        avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n\n        # Validation\n        model.eval()\n        total_val_loss = 0\n        total_val_accuracy = 0\n        all_preds = []\n        all_labels = []\n\n        for batch in val_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n\n            # Move tensors to the same device\n            b_input_ids = b_input_ids.to(device)\n            b_input_mask = b_input_mask.to(device)\n            b_labels = b_labels.to(device)\n\n            with torch.no_grad():\n                outputs = model(b_input_ids, b_input_mask)\n                loss = nn.CrossEntropyLoss()(outputs, b_labels)\n                total_val_loss += loss.item()\n\n                logits = outputs.detach().cpu().numpy()\n                label_ids = b_labels.cpu().numpy()\n                total_val_accuracy += flat_accuracy(logits, label_ids)\n\n                all_preds.extend(np.argmax(logits, axis=1).flatten())\n                all_labels.extend(label_ids.flatten())\n\n        avg_val_loss = total_val_loss / len(val_dataloader)\n        avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n        elapsed_time = time.time() - start_time\n\n        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Train Accuracy: {avg_train_accuracy:.4f}\")\n        print(f\"Validation Loss: {avg_val_loss:.4f} | Validation Accuracy: {avg_val_accuracy:.4f}\")\n        print(f\"Time: {elapsed_time:.2f} seconds\")\n\n        # Save best model\n        if avg_val_accuracy > best_val_accuracy:\n            best_val_accuracy = avg_val_accuracy\n            best_model = model.state_dict()\n            best_params = params\n            torch.save(best_model, 'best_model.pth')\n            print(f\"New best model saved with accuracy: {best_val_accuracy:.4f}\")\n\n# Generate classification report\nprint(\"Classification Report:\")\nprint(classification_report(all_labels, all_preds))\n\n\n\n# Define search space for hyperparameters\nepochs = 5\nlearning_rates = [2e-5, 3e-5, 5e-5]\nbatch_sizes = [16, 32]\noptimizers = ['adamw', 'adam', 'rmsprop', 'sgd']\n\n# Number of random samples to try\nnum_samples = 5\n\n# Function to calculate accuracy\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n# Function to get optimizer\ndef get_optimizer(optimizer_name, model_parameters, lr):\n    if optimizer_name == 'adamw':\n        return optim.AdamW(model_parameters, lr=lr)\n    elif optimizer_name == 'adam':\n        return optim.Adam(model_parameters, lr=lr)\n    elif optimizer_name == 'rmsprop':\n        return optim.RMSprop(model_parameters, lr=lr)\n    elif optimizer_name == 'sgd':\n        return optim.SGD(model_parameters, lr=lr)\n\n# Randomly sample hyperparameter combinations\nrandom_hyperparams = [\n    {\n        \"optimizer\": random.choice(optimizers),\n        \"learning_rate\": random.choice(learning_rates),\n        \"batch_size\": random.choice(batch_sizes),\n    }\n    for _ in range(num_samples)\n]\n\nbest_accuracy = 0\nbest_params = {}\n\n# Iterate over randomly chosen hyperparameter sets\nfor params in random_hyperparams:\n    optimizer_name = params[\"optimizer\"]\n    lr = params[\"learning_rate\"]\n    batch_size = params[\"batch_size\"]\n\n    # Initialize data loaders\n    train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n    val_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=batch_size)\n\n    # Define optimizer and scheduler\n    optimizer = get_optimizer(optimizer_name, model.parameters(), lr)\n    total_steps = len(train_dataloader) * epochs\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n    # Move model to device\n    model.to(device)\n\n    for epoch in range(epochs):\n        start_time = time.time()\n\n        # Training\n        model.train()\n        total_train_loss = 0\n        total_train_accuracy = 0\n        for batch in train_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            b_input_ids, b_input_mask, b_labels = b_input_ids.to(device), b_input_mask.to(device), b_labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(b_input_ids, b_input_mask)\n            loss = nn.CrossEntropyLoss()(outputs, b_labels)\n            total_train_loss += loss.item()\n\n            logits = outputs.detach().cpu().numpy()\n            label_ids = b_labels.cpu().numpy()\n            total_train_accuracy += flat_accuracy(logits, label_ids)\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        avg_train_loss = total_train_loss / len(train_dataloader)\n        avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n\n        # Validation\n        model.eval()\n        total_val_loss = 0\n        total_val_accuracy = 0\n        for batch in val_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            b_input_ids, b_input_mask, b_labels = b_input_ids.to(device), b_input_mask.to(device), b_labels.to(device)\n\n            with torch.no_grad():\n                outputs = model(b_input_ids, b_input_mask)\n                loss = nn.CrossEntropyLoss()(outputs, b_labels)\n                total_val_loss += loss.item()\n\n                logits = outputs.detach().cpu().numpy()\n                label_ids = b_labels.cpu().numpy()\n                total_val_accuracy += flat_accuracy(logits, label_ids)\n\n        avg_val_loss = total_val_loss / len(val_dataloader)\n        avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n\n        elapsed_time = time.time() - start_time\n\n        print(f\"Optimizer: {optimizer_name} | Learning Rate: {lr} | Batch Size: {batch_size}\")\n        print(f\"Epoch {epoch+1}\")\n        print(f\"Train Loss: {avg_train_loss:.4f} | Train Accuracy: {avg_train_accuracy:.4f}\")\n        print(f\"Validation Loss: {avg_val_loss:.4f} | Validation Accuracy: {avg_val_accuracy:.4f}\")\n        print(f\"Time: {elapsed_time:.2f} seconds\")\n        print(\"-\" * 50)\n\n        # Update best parameters if validation accuracy improves\n        if avg_val_accuracy > best_accuracy:\n            best_accuracy = avg_val_accuracy\n            best_params = {\"optimizer\": optimizer_name, \"learning_rate\": lr, \"batch_size\": batch_size}\n\nprint(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\nprint(f\"Best Parameters: Optimizer = {best_params['optimizer']}, Learning Rate = {best_params['learning_rate']}, Batch Size = {best_params['batch_size']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T16:01:20.079930Z","iopub.execute_input":"2026-02-14T16:01:20.081093Z","iopub.status.idle":"2026-02-14T18:05:03.364221Z","shell.execute_reply.started":"2026-02-14T16:01:20.081069Z","shell.execute_reply":"2026-02-14T18:05:03.363442Z"}},"outputs":[{"name":"stdout","text":"Collecting pennylane\n  Downloading pennylane-0.44.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.15.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.5)\nCollecting rustworkx>=0.14.0 (from pennylane)\n  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\nCollecting appdirs (from pennylane)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nCollecting autoray==0.8.2 (from pennylane)\n  Downloading autoray-0.8.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\nCollecting pennylane-lightning>=0.44 (from pennylane)\n  Downloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.5)\nRequirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (26.0rc2)\nCollecting diastatic-malt (from pennylane)\n  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\nCollecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.44->pennylane)\n  Downloading scipy_openblas32-0.3.31.22.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\nRequirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.1.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\nRequirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\nDownloading pennylane-0.44.0-py3-none-any.whl (5.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading autoray-0.8.2-py3-none-any.whl (935 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m935.6/935.6 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy_openblas32-0.3.31.22.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\nSuccessfully installed appdirs-1.4.4 autoray-0.8.2 diastatic-malt-2.15.2 pennylane-0.44.0 pennylane-lightning-0.44.0 rustworkx-0.17.1 scipy-openblas32-0.3.31.22.1\n                                                text  label\n0  with its dogged hollywood naturalism and the i...      0\n1  . . . has its moments , but ultimately , its c...      0\n2  leigh 's film is full of memorable performance...      1\n3  the code talkers deserved better than a hollow...      0\n4     i have to admit that i am baffled by jason x .      0\n(10662, 2)\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"                                                text  label  \\\n0  with its dogged hollywood naturalism and the i...      0   \n1  . . . has its moments , but ultimately , its c...      0   \n2  leigh 's film is full of memorable performance...      1   \n3  the code talkers deserved better than a hollow...      0   \n4     i have to admit that i am baffled by jason x .      0   \n\n                                        cleaned_text  \n0  dogged hollywood naturalism inexorable passage...  \n1  moments ultimately curmudgeon nt quite make cu...  \n2  leigh film full memorable performances top bottom  \n3        code talkers deserved better hollow tribute  \n4                              admit baffled jason x  \nlabel\n0    5331\n1    5331\nName: count, dtype: int64\nBalanced Class Distribution:\nlabel\n0    10662\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5201ed4a334d49ec88f9d6ab8109961b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e574847bcfb04724ac32b039db58f465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"773dde43ca8b480ba4f9f9f738216937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"996cd926d7cc4d9f8e11c2e094f41fb9"}},"metadata":{}},{"name":"stderr","text":"2026-02-14 16:01:53.171983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771084913.522792      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771084913.626673      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771084914.509725      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771084914.509774      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771084914.509777      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771084914.509780      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b09867755b5249718331caa177d70a4e"}},"metadata":{}},{"name":"stdout","text":"Testing configuration 1: {'learning_rate': 1e-05, 'epochs': 7, 'batch_size': 16}\nEpoch 1 | Train Loss: 0.6196 | Train Accuracy: 0.6436\nValidation Loss: 0.5534 | Validation Accuracy: 0.7150\nTime: 130.62 seconds\nNew best model saved with accuracy: 0.7150\nEpoch 2 | Train Loss: 0.4906 | Train Accuracy: 0.7663\nValidation Loss: 0.5121 | Validation Accuracy: 0.7534\nTime: 137.91 seconds\nNew best model saved with accuracy: 0.7534\nEpoch 3 | Train Loss: 0.4079 | Train Accuracy: 0.8144\nValidation Loss: 0.5210 | Validation Accuracy: 0.7511\nTime: 137.44 seconds\nEpoch 4 | Train Loss: 0.3328 | Train Accuracy: 0.8606\nValidation Loss: 0.5546 | Validation Accuracy: 0.7567\nTime: 141.75 seconds\nNew best model saved with accuracy: 0.7567\nEpoch 5 | Train Loss: 0.2766 | Train Accuracy: 0.8897\nValidation Loss: 0.5869 | Validation Accuracy: 0.7595\nTime: 143.96 seconds\nNew best model saved with accuracy: 0.7595\nEpoch 6 | Train Loss: 0.2309 | Train Accuracy: 0.9151\nValidation Loss: 0.6147 | Validation Accuracy: 0.7581\nTime: 140.38 seconds\nEpoch 7 | Train Loss: 0.2116 | Train Accuracy: 0.9229\nValidation Loss: 0.6244 | Validation Accuracy: 0.7586\nTime: 139.93 seconds\nTesting configuration 2: {'learning_rate': 1e-05, 'epochs': 5, 'batch_size': 32}\nEpoch 1 | Train Loss: 0.2302 | Train Accuracy: 0.9119\nValidation Loss: 0.6423 | Validation Accuracy: 0.7525\nTime: 139.81 seconds\nEpoch 2 | Train Loss: 0.1637 | Train Accuracy: 0.9421\nValidation Loss: 0.7117 | Validation Accuracy: 0.7584\nTime: 139.35 seconds\nEpoch 3 | Train Loss: 0.1326 | Train Accuracy: 0.9563\nValidation Loss: 0.7665 | Validation Accuracy: 0.7425\nTime: 139.58 seconds\nEpoch 4 | Train Loss: 0.1053 | Train Accuracy: 0.9685\nValidation Loss: 0.7896 | Validation Accuracy: 0.7464\nTime: 139.61 seconds\nEpoch 5 | Train Loss: 0.0861 | Train Accuracy: 0.9743\nValidation Loss: 0.8001 | Validation Accuracy: 0.7570\nTime: 139.56 seconds\nTesting configuration 3: {'learning_rate': 1e-05, 'epochs': 3, 'batch_size': 16}\nEpoch 1 | Train Loss: 0.1032 | Train Accuracy: 0.9659\nValidation Loss: 0.8243 | Validation Accuracy: 0.7530\nTime: 140.07 seconds\nEpoch 2 | Train Loss: 0.0719 | Train Accuracy: 0.9787\nValidation Loss: 0.8869 | Validation Accuracy: 0.7474\nTime: 140.30 seconds\nEpoch 3 | Train Loss: 0.0582 | Train Accuracy: 0.9834\nValidation Loss: 0.8952 | Validation Accuracy: 0.7546\nTime: 139.60 seconds\nTesting configuration 4: {'learning_rate': 3e-05, 'epochs': 5, 'batch_size': 32}\nEpoch 1 | Train Loss: 0.1307 | Train Accuracy: 0.9523\nValidation Loss: 0.8272 | Validation Accuracy: 0.7369\nTime: 140.13 seconds\nEpoch 2 | Train Loss: 0.0767 | Train Accuracy: 0.9745\nValidation Loss: 0.8490 | Validation Accuracy: 0.7495\nTime: 140.12 seconds\nEpoch 3 | Train Loss: 0.0520 | Train Accuracy: 0.9836\nValidation Loss: 0.9616 | Validation Accuracy: 0.7532\nTime: 140.04 seconds\nEpoch 4 | Train Loss: 0.0315 | Train Accuracy: 0.9906\nValidation Loss: 1.0304 | Validation Accuracy: 0.7588\nTime: 139.78 seconds\nEpoch 5 | Train Loss: 0.0204 | Train Accuracy: 0.9947\nValidation Loss: 1.0523 | Validation Accuracy: 0.7567\nTime: 139.86 seconds\nTesting configuration 5: {'learning_rate': 5e-05, 'epochs': 7, 'batch_size': 16}\nEpoch 1 | Train Loss: 0.0939 | Train Accuracy: 0.9676\nValidation Loss: 0.9088 | Validation Accuracy: 0.7598\nTime: 140.16 seconds\nNew best model saved with accuracy: 0.7598\nEpoch 2 | Train Loss: 0.0557 | Train Accuracy: 0.9814\nValidation Loss: 0.8785 | Validation Accuracy: 0.7646\nTime: 140.68 seconds\nNew best model saved with accuracy: 0.7646\nEpoch 3 | Train Loss: 0.0404 | Train Accuracy: 0.9867\nValidation Loss: 1.0398 | Validation Accuracy: 0.7446\nTime: 141.96 seconds\nEpoch 4 | Train Loss: 0.0245 | Train Accuracy: 0.9922\nValidation Loss: 1.1210 | Validation Accuracy: 0.7567\nTime: 144.97 seconds\nEpoch 5 | Train Loss: 0.0135 | Train Accuracy: 0.9953\nValidation Loss: 1.1478 | Validation Accuracy: 0.7686\nTime: 143.65 seconds\nNew best model saved with accuracy: 0.7686\nEpoch 6 | Train Loss: 0.0107 | Train Accuracy: 0.9967\nValidation Loss: 1.1543 | Validation Accuracy: 0.7625\nTime: 143.38 seconds\nEpoch 7 | Train Loss: 0.0041 | Train Accuracy: 0.9989\nValidation Loss: 1.1829 | Validation Accuracy: 0.7614\nTime: 143.51 seconds\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.77      0.74      0.76      1068\n           1       0.75      0.78      0.77      1065\n\n    accuracy                           0.76      2133\n   macro avg       0.76      0.76      0.76      2133\nweighted avg       0.76      0.76      0.76      2133\n\nOptimizer: rmsprop | Learning Rate: 2e-05 | Batch Size: 32\nEpoch 1\nTrain Loss: 0.0367 | Train Accuracy: 0.9915\nValidation Loss: 1.1968 | Validation Accuracy: 0.7581\nTime: 141.11 seconds\n--------------------------------------------------\nOptimizer: rmsprop | Learning Rate: 2e-05 | Batch Size: 32\nEpoch 2\nTrain Loss: 0.0107 | Train Accuracy: 0.9966\nValidation Loss: 1.2155 | Validation Accuracy: 0.7532\nTime: 141.41 seconds\n--------------------------------------------------\nOptimizer: rmsprop | Learning Rate: 2e-05 | Batch Size: 32\nEpoch 3\nTrain Loss: 0.0030 | Train Accuracy: 0.9993\nValidation Loss: 1.4016 | Validation Accuracy: 0.7551\nTime: 141.51 seconds\n--------------------------------------------------\nOptimizer: rmsprop | Learning Rate: 2e-05 | Batch Size: 32\nEpoch 4\nTrain Loss: 0.0047 | Train Accuracy: 0.9986\nValidation Loss: 1.4119 | Validation Accuracy: 0.7567\nTime: 138.10 seconds\n--------------------------------------------------\nOptimizer: rmsprop | Learning Rate: 2e-05 | Batch Size: 32\nEpoch 5\nTrain Loss: 0.0030 | Train Accuracy: 0.9988\nValidation Loss: 1.4101 | Validation Accuracy: 0.7562\nTime: 141.01 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 1\nTrain Loss: 0.0200 | Train Accuracy: 0.9944\nValidation Loss: 1.2880 | Validation Accuracy: 0.7649\nTime: 145.97 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 2\nTrain Loss: 0.0065 | Train Accuracy: 0.9975\nValidation Loss: 1.3967 | Validation Accuracy: 0.7463\nTime: 146.77 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 3\nTrain Loss: 0.0049 | Train Accuracy: 0.9987\nValidation Loss: 1.3768 | Validation Accuracy: 0.7645\nTime: 146.28 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 4\nTrain Loss: 0.0016 | Train Accuracy: 0.9998\nValidation Loss: 1.4617 | Validation Accuracy: 0.7612\nTime: 146.19 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 5\nTrain Loss: 0.0018 | Train Accuracy: 0.9994\nValidation Loss: 1.4248 | Validation Accuracy: 0.7631\nTime: 145.89 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 1\nTrain Loss: 0.0108 | Train Accuracy: 0.9965\nValidation Loss: 1.3577 | Validation Accuracy: 0.7631\nTime: 146.33 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 2\nTrain Loss: 0.0042 | Train Accuracy: 0.9982\nValidation Loss: 1.4307 | Validation Accuracy: 0.7631\nTime: 144.21 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 3\nTrain Loss: 0.0037 | Train Accuracy: 0.9989\nValidation Loss: 1.3663 | Validation Accuracy: 0.7649\nTime: 142.22 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 4\nTrain Loss: 0.0028 | Train Accuracy: 0.9991\nValidation Loss: 1.4131 | Validation Accuracy: 0.7612\nTime: 146.13 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 5\nTrain Loss: 0.0013 | Train Accuracy: 0.9998\nValidation Loss: 1.3853 | Validation Accuracy: 0.7673\nTime: 146.00 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 1\nTrain Loss: 0.0066 | Train Accuracy: 0.9980\nValidation Loss: 1.5470 | Validation Accuracy: 0.7583\nTime: 143.09 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 2\nTrain Loss: 0.0100 | Train Accuracy: 0.9970\nValidation Loss: 1.3276 | Validation Accuracy: 0.7586\nTime: 143.49 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 3\nTrain Loss: 0.0028 | Train Accuracy: 0.9991\nValidation Loss: 1.5153 | Validation Accuracy: 0.7551\nTime: 143.78 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 4\nTrain Loss: 0.0019 | Train Accuracy: 0.9995\nValidation Loss: 1.4563 | Validation Accuracy: 0.7646\nTime: 143.38 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 5\nTrain Loss: 0.0005 | Train Accuracy: 1.0000\nValidation Loss: 1.4834 | Validation Accuracy: 0.7646\nTime: 143.25 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 1\nTrain Loss: 0.0073 | Train Accuracy: 0.9984\nValidation Loss: 1.5705 | Validation Accuracy: 0.7649\nTime: 142.90 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 2\nTrain Loss: 0.0043 | Train Accuracy: 0.9989\nValidation Loss: 1.5939 | Validation Accuracy: 0.7444\nTime: 141.22 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 3\nTrain Loss: 0.0018 | Train Accuracy: 0.9994\nValidation Loss: 1.4685 | Validation Accuracy: 0.7724\nTime: 141.17 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 4\nTrain Loss: 0.0014 | Train Accuracy: 0.9995\nValidation Loss: 1.4841 | Validation Accuracy: 0.7696\nTime: 141.39 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 2e-05 | Batch Size: 16\nEpoch 5\nTrain Loss: 0.0005 | Train Accuracy: 0.9998\nValidation Loss: 1.5041 | Validation Accuracy: 0.7710\nTime: 139.35 seconds\n--------------------------------------------------\nBest Validation Accuracy: 0.7724\nBest Parameters: Optimizer = adamw, Learning Rate = 2e-05, Batch Size = 16\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, confusion_matrix,\n    classification_report, roc_curve)\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\ndef evaluate_binary_model(model, dataloader, device):\n    model.eval()\n    all_true_labels = []\n    all_probs = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            b_input_ids = b_input_ids.to(device)\n            b_input_mask = b_input_mask.to(device)\n            b_labels = b_labels.to(device)\n\n            outputs = model(b_input_ids, b_input_mask)\n            probs = torch.softmax(outputs, dim=1)\n\n            all_true_labels.append(b_labels.cpu().numpy())\n            all_probs.append(probs.cpu().numpy())\n\n    # Convert to numpy\n    all_true_labels = np.concatenate(all_true_labels)\n    all_probs = np.concatenate(all_probs)\n    all_preds = np.argmax(all_probs, axis=1)\n\n    # ================= Metrics =================\n    tn, fp, fn, tp = confusion_matrix(all_true_labels, all_preds).ravel()\n\n    accuracy = accuracy_score(all_true_labels, all_preds)\n    precision = precision_score(all_true_labels, all_preds)\n    recall = recall_score(all_true_labels, all_preds)          # Sensitivity\n    specificity = tn / (tn + fp)\n    f1 = f1_score(all_true_labels, all_preds)\n    auc = roc_auc_score(all_true_labels, all_probs[:, 1])\n\n    # ================= Print metrics =================\n    print(\"===== Evaluation Metrics =====\")\n    print(f\"Accuracy     : {accuracy:.4f}\")\n    print(f\"Precision    : {precision:.4f}\")\n    print(f\"Recall       : {recall:.4f}\")\n    print(f\"Sensitivity : {recall:.4f}\")\n    print(f\"Specificity : {specificity:.4f}\")\n    print(f\"F1-score    : {f1:.4f}\")\n    print(f\"AUC         : {auc:.4f}\")\n\n    # ================= Classification Report =================\n    print(\"\\n===== Classification Report =====\")\n    print(classification_report(all_true_labels, all_preds, digits=4))\n\n    # ================= ROC Curve (Both Classes) =================\n    fpr_0, tpr_0, _ = roc_curve(all_true_labels, all_probs[:, 0], pos_label=0)\n    fpr_1, tpr_1, _ = roc_curve(all_true_labels, all_probs[:, 1], pos_label=1)\n\n    auc_0 = roc_auc_score(1 - all_true_labels, all_probs[:, 0])\n    auc_1 = roc_auc_score(all_true_labels, all_probs[:, 1])\n\n    plt.figure(figsize=(7, 6))\n    plt.plot(fpr_0, tpr_0, label=f\"Class 0 ROC (AUC = {auc_0:.2f})\", lw=2)\n    plt.plot(fpr_1, tpr_1, label=f\"Class 1 ROC (AUC = {auc_1:.2f})\", lw=2)\n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve for Binary Classification\")\n    plt.legend(loc=\"lower right\")\n    plt.grid()\n    plt.tight_layout()\n    plt.show()\n\n    return accuracy, precision, recall, specificity, f1, auc\n\n\naccuracy, precision, recall, specificity, f1, auc = evaluate_binary_model(\n    model, val_dataloader, device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T18:06:52.672618Z","iopub.execute_input":"2026-02-14T18:06:52.672936Z","iopub.status.idle":"2026-02-14T18:07:06.053401Z","shell.execute_reply.started":"2026-02-14T18:06:52.672911Z","shell.execute_reply":"2026-02-14T18:07:06.052663Z"}},"outputs":[{"name":"stdout","text":"===== Evaluation Metrics =====\nAccuracy     : 0.7698\nPrecision    : 0.7749\nRecall       : 0.7596\nSensitivity : 0.7596\nSpecificity : 0.7800\nF1-score    : 0.7672\nAUC         : 0.8392\n\n===== Classification Report =====\n              precision    recall  f1-score   support\n\n           0     0.7649    0.7800    0.7724      1068\n           1     0.7749    0.7596    0.7672      1065\n\n    accuracy                         0.7698      2133\n   macro avg     0.7699    0.7698    0.7698      2133\nweighted avg     0.7699    0.7698    0.7698      2133\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 700x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"\n!pip install pennylane\n# ===============================\n# Imports & Setup\n# ===============================\nimport re, warnings\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport pennylane as qml\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n)\n\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nfrom transformers import AutoTokenizer, AutoModel\nfrom torch.optim import AdamW\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nwarnings.filterwarnings(\"ignore\")\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\nds = load_dataset(\"mattymchen/mr\")\n# Convert train split to pandas (MPQA already split)\ndf = ds[\"test\"].to_pandas()\n\n# ===============================\n# Dataset Preprocessing\n# ===============================\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n    text = re.sub(r\"\\d+\", \"\", text)\n    words = [w for w in text.split() if w not in stop_words]\n    return \" \".join(words)\n\n# Load your dataset\n# Replace this with your own df loading if not already loaded\n# df = pd.read_csv(\"your_dataset.csv\")\n\ndf[\"cleaned_text\"] = df[\"text\"].astype(str).apply(clean_text)\n\nle = LabelEncoder()\ndf[\"label\"] = le.fit_transform(df[\"label\"])\nmin_class = df[\"label\"].value_counts().min()\n\n# Balance classes\ndf_balanced = (\n    df.groupby(\"label\", group_keys=False)\n      .apply(lambda x: x.sample(min_class, random_state=42))\n      .sample(frac=1, random_state=42)\n)\n\n# Tokenize\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ntokens = tokenizer(\n    df_balanced[\"cleaned_text\"].tolist(),\n    padding=\"max_length\",\n    truncation=True,\n    max_length=128,\n    return_tensors=\"pt\"\n)\n\ninput_ids = tokens[\"input_ids\"]\nattention_mask = tokens[\"attention_mask\"]\nlabels = torch.tensor(df_balanced[\"label\"].values)\n\nX_train, X_val, y_train, y_val, m_train, m_val = train_test_split(\n    input_ids, labels, attention_mask, test_size=0.2, random_state=42\n)\n\ntrain_data = TensorDataset(X_train, m_train, y_train)\nval_data = TensorDataset(X_val, m_val, y_val)\n\ntrain_loader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=16)\nval_loader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=16)\n\n\n# ===============================\n# Quantum Circuits\n# ===============================\ndev = qml.device(\"default.qubit\", wires=2)\n\n@qml.qnode(dev, interface=\"torch\")\ndef qc1(weights, x):\n    qml.Hadamard(0)\n    qml.Hadamard(1)\n    qml.RX(x[0], 0)\n    qml.RY(x[1], 1)\n    qml.CNOT([0,1])\n    qml.RZ(weights[0], 0)\n    qml.RZ(weights[1], 1)\n    return qml.expval(qml.PauliZ(0))\n\n@qml.qnode(dev, interface=\"torch\")\ndef qc2(weights, x):\n    qml.Hadamard(0)\n    qml.RY(x[0], 0)\n    qml.RX(x[1], 1)\n    qml.CNOT([1,0])\n    qml.RX(weights[0], 0)\n    qml.RY(weights[1], 1)\n    return qml.expval(qml.PauliZ(0))\n\n@qml.qnode(dev, interface=\"torch\")\ndef qc3(weights, x):\n    for i in range(2):\n        qml.Hadamard(i)\n        qml.RX(x[i], i)\n        qml.RY(weights[i], i)\n        qml.RZ(weights[i], i)\n    qml.CNOT([0,1])\n    return qml.expval(qml.PauliZ(1))\n\n@qml.qnode(dev, interface=\"torch\")\ndef qc4(weights, x):\n    qml.Hadamard(0)\n    qml.CNOT([0,1])\n    qml.RX(x[0], 0)\n    qml.RY(x[1], 1)\n    qml.CNOT([1,0])\n    qml.RZ(weights[0], 0)\n    qml.RZ(weights[1], 1)\n    return qml.expval(qml.PauliZ(0))\n\n\nQUANTUM_CIRCUITS = {\n    \"QC1\": qc1,\n    \"QC2\": qc2,\n    \"QC3\": qc3,\n    \"QC4\": qc4\n}\n\n\n# ===============================\n# Hybrid QBiLSTM Model\n# ===============================\nclass QBiLSTM(nn.Module):\n    def __init__(self, quantum_circuit):\n        super().__init__()\n        self.qc = quantum_circuit\n        self.q_weights = nn.Parameter(torch.randn(2))\n\n        self.encoder = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n\n        self.bilstm = nn.LSTM(\n            input_size=768,\n            hidden_size=128,\n            bidirectional=True,\n            batch_first=True\n        )\n\n        # Include quantum output\n        self.fc = nn.Linear(256 + 1, 2)\n\n    def quantum_layer(self, x):\n        q_outs = []\n        for v in x:\n            vec = torch.tanh(v[:2]).detach().cpu() * np.pi\n            q_val = self.qc(self.q_weights, vec)\n            q_outs.append(q_val)\n        q_outs = torch.stack(q_outs).unsqueeze(1)\n        return q_outs.to(x.device).float()\n\n    def forward(self, input_ids, attention_mask):\n        enc = self.encoder(input_ids, attention_mask).last_hidden_state\n        lstm_out, _ = self.bilstm(enc)\n        h = lstm_out[:, -1, :]\n        q_feat = self.quantum_layer(h)\n        combined = torch.cat([h, q_feat], dim=1)\n        return self.fc(combined)\n\n\n# ===============================\n# Training & Evaluation\n# ===============================\nresults = {}\n\nfor name, qc in QUANTUM_CIRCUITS.items():\n    print(f\"\\n====== Training {name} ======\")\n\n    model = QBiLSTM(qc).to(device)\n    optimizer = AdamW(model.parameters(), lr=2e-5)\n    loss_fn = nn.CrossEntropyLoss()\n\n    EPOCHS = 10\n\n    for epoch in range(EPOCHS):\n        model.train()\n        total_loss = 0\n\n        for step, batch in enumerate(train_loader, 1):\n            ids, mask, y = [b.to(device) for b in batch]\n            optimizer.zero_grad()\n            logits = model(ids, mask)\n            loss = loss_fn(logits, y)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Avg Loss: {total_loss/len(train_loader):.4f}\")\n\n    # -------------------------------\n    # Evaluation\n    # -------------------------------\n    model.eval()\n    preds, gold, probs = [], [], []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            ids, mask, y = [b.to(device) for b in batch]\n            logits = model(ids, mask)\n            prob = torch.softmax(logits, dim=1)\n            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n            probs.extend(prob[:, 1].cpu().numpy())\n            gold.extend(y.cpu().numpy())\n\n    preds = np.array(preds)\n    gold = np.array(gold)\n    probs = np.array(probs)\n\n    accuracy = accuracy_score(gold, preds)\n    precision = precision_score(gold, preds)\n    recall = recall_score(gold, preds)\n    f1 = f1_score(gold, preds)\n    auc = roc_auc_score(gold, probs)\n    tn, fp, fn, tp = confusion_matrix(gold, preds).ravel()\n    specificity = tn / (tn + fp)\n\n    results[name] = {\n        \"Accuracy\": accuracy,\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"Specificity\": specificity,\n        \"F1\": f1,\n        \"AUC\": auc\n    }\n\n    print(f\"\\n{name} Results:\")\n    print(f\"Accuracy     : {accuracy:.4f}\")\n    print(f\"Precision    : {precision:.4f}\")\n    print(f\"Recall       : {recall:.4f}\")\n    print(f\"Specificity  : {specificity:.4f}\")\n    print(f\"F1-score     : {f1:.4f}\")\n    print(f\"AUC          : {auc:.4f}\")\n\n\n# ===============================\n# Final Comparison Table\n# ===============================\nprint(\"\\n===== FINAL QUANTUM CIRCUIT COMPARISON =====\")\nfor k, v in results.items():\n    print(f\"\\n{k}\")\n    for metric, value in v.items():\n        print(f\"{metric:12s}: {value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T05:18:43.274534Z","iopub.execute_input":"2026-02-15T05:18:43.274907Z","iopub.status.idle":"2026-02-15T06:25:01.357800Z","shell.execute_reply.started":"2026-02-15T05:18:43.274868Z","shell.execute_reply":"2026-02-15T06:25:01.357133Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.44.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.15.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.5)\nRequirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\nRequirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\nRequirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\nRequirement already satisfied: autoray==0.8.2 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.2)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\nRequirement already satisfied: pennylane-lightning>=0.44 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.44.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.5)\nRequirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (26.0rc2)\nRequirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\nRequirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning>=0.44->pennylane) (0.3.31.22.1)\nRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\nRequirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.1.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\nRequirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"\n====== Training QC1 ======\nEpoch 1/10 | Avg Loss: 0.5144\nEpoch 2/10 | Avg Loss: 0.3376\nEpoch 3/10 | Avg Loss: 0.1824\nEpoch 4/10 | Avg Loss: 0.0954\nEpoch 5/10 | Avg Loss: 0.0568\nEpoch 6/10 | Avg Loss: 0.0400\nEpoch 7/10 | Avg Loss: 0.0330\nEpoch 8/10 | Avg Loss: 0.0261\nEpoch 9/10 | Avg Loss: 0.0181\nEpoch 10/10 | Avg Loss: 0.0185\n\nQC1 Results:\nAccuracy     : 0.8036\nPrecision    : 0.8256\nRecall       : 0.7546\nSpecificity  : 0.8497\nF1-score     : 0.7885\nAUC          : 0.8794\n\n====== Training QC2 ======\nEpoch 1/10 | Avg Loss: 0.5256\nEpoch 2/10 | Avg Loss: 0.3539\nEpoch 3/10 | Avg Loss: 0.1937\nEpoch 4/10 | Avg Loss: 0.0997\nEpoch 5/10 | Avg Loss: 0.0615\nEpoch 6/10 | Avg Loss: 0.0448\nEpoch 7/10 | Avg Loss: 0.0324\nEpoch 8/10 | Avg Loss: 0.0281\nEpoch 9/10 | Avg Loss: 0.0168\nEpoch 10/10 | Avg Loss: 0.0217\n\nQC2 Results:\nAccuracy     : 0.8050\nPrecision    : 0.7874\nRecall       : 0.8193\nSpecificity  : 0.7914\nF1-score     : 0.8030\nAUC          : 0.8826\n\n====== Training QC3 ======\nEpoch 1/10 | Avg Loss: 0.5236\nEpoch 2/10 | Avg Loss: 0.3502\nEpoch 3/10 | Avg Loss: 0.1914\nEpoch 4/10 | Avg Loss: 0.0957\nEpoch 5/10 | Avg Loss: 0.0579\nEpoch 6/10 | Avg Loss: 0.0433\nEpoch 7/10 | Avg Loss: 0.0311\nEpoch 8/10 | Avg Loss: 0.0277\nEpoch 9/10 | Avg Loss: 0.0189\nEpoch 10/10 | Avg Loss: 0.0211\n\nQC3 Results:\nAccuracy     : 0.7928\nPrecision    : 0.7469\nRecall       : 0.8667\nSpecificity  : 0.7231\nF1-score     : 0.8023\nAUC          : 0.8847\n\n====== Training QC4 ======\nEpoch 1/10 | Avg Loss: 0.5247\nEpoch 2/10 | Avg Loss: 0.3437\nEpoch 3/10 | Avg Loss: 0.1879\nEpoch 4/10 | Avg Loss: 0.0934\nEpoch 5/10 | Avg Loss: 0.0597\nEpoch 6/10 | Avg Loss: 0.0331\nEpoch 7/10 | Avg Loss: 0.0266\nEpoch 8/10 | Avg Loss: 0.0273\nEpoch 9/10 | Avg Loss: 0.0229\nEpoch 10/10 | Avg Loss: 0.0152\n\nQC4 Results:\nAccuracy     : 0.7947\nPrecision    : 0.8404\nRecall       : 0.7121\nSpecificity  : 0.8725\nF1-score     : 0.7709\nAUC          : 0.8800\n\n===== FINAL QUANTUM CIRCUIT COMPARISON =====\n\nQC1\nAccuracy    : 0.8036\nPrecision   : 0.8256\nRecall      : 0.7546\nSpecificity : 0.8497\nF1          : 0.7885\nAUC         : 0.8794\n\nQC2\nAccuracy    : 0.8050\nPrecision   : 0.7874\nRecall      : 0.8193\nSpecificity : 0.7914\nF1          : 0.8030\nAUC         : 0.8826\n\nQC3\nAccuracy    : 0.7928\nPrecision   : 0.7469\nRecall      : 0.8667\nSpecificity : 0.7231\nF1          : 0.8023\nAUC         : 0.8847\n\nQC4\nAccuracy    : 0.7947\nPrecision   : 0.8404\nRecall      : 0.7121\nSpecificity : 0.8725\nF1          : 0.7709\nAUC         : 0.8800\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    roc_auc_score,\n    confusion_matrix\n)\n\n# Evaluation\nmodel.eval()\npreds, gold, probs = [], [], []\n\nwith torch.no_grad():\n    for batch in val_loader:\n        ids, mask, y = [b.to(device) for b in batch]\n        logits = model(ids, mask)\n\n        probabilities = torch.softmax(logits, dim=1)\n\n        preds.extend(torch.argmax(logits, 1).cpu().numpy())\n        probs.extend(probabilities[:, 1].cpu().numpy())  # positive class prob\n        gold.extend(y.cpu().numpy())\n\n# Convert to numpy\npreds = np.array(preds)\ngold = np.array(gold)\nprobs = np.array(probs)\n\n# Basic metrics\naccuracy = accuracy_score(gold, preds)\nprecision = precision_score(gold, preds)\nrecall = recall_score(gold, preds)\nf1 = f1_score(gold, preds)\nauc = roc_auc_score(gold, probs)\n\n# Confusion Matrix for Specificity\ntn, fp, fn, tp = confusion_matrix(gold, preds).ravel()\nspecificity = tn / (tn + fp)\n\n# Store results\nresults[name] = {\n    \"Accuracy\": accuracy,\n    \"Precision\": precision,\n    \"Recall\": recall,\n    \"Specificity\": specificity,\n    \"F1\": f1,\n    \"AUC\": auc\n}\n\n# Print nicely\nprint(f\"\\n{name} Results:\")\nprint(f\"Accuracy     : {accuracy:.4f}\")\nprint(f\"Precision    : {precision:.4f}\")\nprint(f\"Recall       : {recall:.4f}\")\nprint(f\"Specificity  : {specificity:.4f}\")\nprint(f\"F1-score     : {f1:.4f}\")\nprint(f\"AUC          : {auc:.4f}\")\nprint(\"\\n===== FINAL QUANTUM CIRCUIT COMPARISON =====\")\n\nfor k, v in results.items():\n    print(f\"\\n{k}\")\n\n    if isinstance(v, dict):\n        for metric, value in v.items():\n            print(f\"{metric:12s}: {value:.4f}\")\n    else:\n        print(f\"Accuracy: {v:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T06:39:33.546576Z","iopub.execute_input":"2026-02-15T06:39:33.547240Z","iopub.status.idle":"2026-02-15T06:39:44.425209Z","shell.execute_reply.started":"2026-02-15T06:39:33.547209Z","shell.execute_reply":"2026-02-15T06:39:44.424621Z"}},"outputs":[{"name":"stdout","text":"\nQC4 Results:\nAccuracy     : 0.7947\nPrecision    : 0.8404\nRecall       : 0.7121\nSpecificity  : 0.8725\nF1-score     : 0.7709\nAUC          : 0.8800\n\n===== FINAL QUANTUM CIRCUIT COMPARISON =====\n\nQC1\nAccuracy    : 0.8036\nPrecision   : 0.8256\nRecall      : 0.7546\nSpecificity : 0.8497\nF1          : 0.7885\nAUC         : 0.8794\n\nQC2\nAccuracy    : 0.8050\nPrecision   : 0.7874\nRecall      : 0.8193\nSpecificity : 0.7914\nF1          : 0.8030\nAUC         : 0.8826\n\nQC3\nAccuracy    : 0.7928\nPrecision   : 0.7469\nRecall      : 0.8667\nSpecificity : 0.7231\nF1          : 0.8023\nAUC         : 0.8847\n\nQC4\nAccuracy    : 0.7947\nPrecision   : 0.8404\nRecall      : 0.7121\nSpecificity : 0.8725\nF1          : 0.7709\nAUC         : 0.8800\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# **DeBARTA**","metadata":{}},{"cell_type":"code","source":"!pip install pennylane\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport torch\nfrom sklearn.metrics import (\n    roc_curve, roc_auc_score, classification_report, confusion_matrix\n)\nfrom sklearn.preprocessing import label_binarize\nimport pennylane as qml\nfrom pennylane import numpy as pnp\nimport re\nimport warnings\nimport re\nimport nltk\n\nfrom nltk.corpus import stopwords\nwarnings.filterwarnings('ignore')\n# Label encoding for 'status' column\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AutoModel\nimport pennylane as qml\n# Convert data to PyTorch DataLoader format\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nimport time\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, roc_curve, auc\nfrom transformers import get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\nfrom sklearn.model_selection import ParameterSampler\nimport random\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport numpy as np\nimport torch\nfrom sklearn.preprocessing import label_binarize\nimport time\nimport random\nimport numpy as np\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom transformers import get_linear_schedule_with_warmup\nfrom transformers import AutoTokenizer, AutoModel\nimport nltk\nfrom nltk.corpus import stopwords\n\nwarnings.filterwarnings(\"ignore\")\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\nds = load_dataset(\"mattymchen/mr\")\n# Convert train split to pandas (MPQA already split)\ndf = ds[\"test\"].to_pandas()\n\n# ===============================\n# Dataset Preprocessing\n# ===============================\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n    text = re.sub(r\"\\d+\", \"\", text)\n    words = [w for w in text.split() if w not in stop_words]\n    return \" \".join(words)\n\n# Load your dataset\n# Replace this with your own df loading if not already loaded\n# df = pd.read_csv(\"your_dataset.csv\")\n\ndf[\"cleaned_text\"] = df[\"text\"].astype(str).apply(clean_text)\n\nle = LabelEncoder()\ndf[\"label\"] = le.fit_transform(df[\"label\"])\nmin_class = df[\"label\"].value_counts().min()\n\n# Balance classes\ndf_balanced = (\n    df.groupby(\"label\", group_keys=False)\n      .apply(lambda x: x.sample(min_class, random_state=42))\n      .sample(frac=1, random_state=42)\n)\n\n\n# Initialize the tokenizer and model from Hugging Face\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n\ntokens = tokenizer.batch_encode_plus(\n    df['cleaned_text'].tolist(),\n    max_length=128,\n    padding=\"max_length\",   # <-- updated\n    truncation=True,\n    return_tensors=\"pt\"\n)\n\n# Convert to tensors\ninput_ids = torch.tensor(tokens['input_ids'])\nattention_masks = torch.tensor(tokens['attention_mask'])\nlabels = torch.tensor(df['label'].values)\n\n# Split the data into training and validation sets\ntrain_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.2)\ntrain_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids, test_size=0.2)\n\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\nval_data = TensorDataset(val_inputs, val_masks, val_labels)\n\ntrain_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=32)\nval_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=32)\n\n# Create a quantum node (circuit)\ndev = qml.device(\"default.qubit\", wires=2)  # or 'default.qubit'\n\n@qml.qnode(dev)\ndef quantum_circuit(weights, inputs):\n    qml.Hadamard(wires=0)\n    qml.Hadamard(wires=1)\n\n    qml.RX(inputs[0], wires=0)\n    qml.RY(inputs[1], wires=1)\n\n    qml.CNOT(wires=[0, 1])\n\n    qml.RZ(weights[0], wires=0)\n    qml.RZ(weights[1], wires=1)\n\n    return qml.expval(qml.PauliZ(0))\n\nclass QBiLSTM(nn.Module):\n    def __init__(self):\n        super(QBiLSTM, self).__init__()\n\n        self.bert = AutoModel.from_pretrained(\"microsoft/deberta-v3-base\")\n\n        # ğŸ” BiLSTM instead of LSTM\n        self.bilstm = nn.LSTM(\n            input_size=768,\n            hidden_size=128,\n            batch_first=True,\n            bidirectional=True\n        )\n\n        # 128 Ã— 2 because BiLSTM\n        self.fc = nn.Linear(256, 2)\n\n    def quantum_layer(self, inputs):\n        processed_features = []\n\n        for feature_vector in inputs:\n            features_for_quantum = feature_vector[:2]\n            q_out = quantum_circuit(\n                torch.randn(2, dtype=torch.float32),\n                features_for_quantum\n            )\n            processed_features.append(q_out)\n\n        return torch.stack(processed_features).unsqueeze(1)\n\n    def forward(self, input_ids, attention_mask):\n        bert_output = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n\n        # BiLSTM output\n        lstm_output, _ = self.bilstm(bert_output.last_hidden_state)\n\n        # Last timestep (batch, 256)\n        last_hidden = lstm_output[:, -1, :]\n\n        _ = self.quantum_layer(last_hidden)\n\n        # Classification\n        output = self.fc(last_hidden)\n        return output\n\n\nmodel = QBiLSTM()\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define hyperparameter search space\nparam_grid = {\n    'learning_rate': [1e-5, 2e-5, 3e-5, 5e-5],\n    'batch_size': [16, 32],\n    'epochs': [3, 5, 7]\n}\n\nnum_samples = 5  \nparam_list = list(ParameterSampler(param_grid, n_iter=num_samples, random_state=42))\n\nbest_model = None\nbest_val_accuracy = 0.0\nbest_params = None\n\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n# Loop through each random set of hyperparameters\nfor idx, params in enumerate(param_list):\n    print(f\"Testing configuration {idx + 1}: {params}\")\n\n    learning_rate = params['learning_rate']\n    batch_size = params['batch_size']\n    epochs = params['epochs']\n\n    # Define optimizer and scheduler\n    optimizer = AdamW(model.parameters(), lr=learning_rate)\n    total_steps = len(train_dataloader) * epochs\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n    for epoch in range(epochs):\n        start_time = time.time()\n        model.train()\n        total_train_loss = 0\n        total_train_accuracy = 0\n\n        for batch in train_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n\n            # Move tensors to the same device\n            b_input_ids = b_input_ids.to(device)\n            b_input_mask = b_input_mask.to(device)\n            b_labels = b_labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(b_input_ids, b_input_mask)\n            loss = nn.CrossEntropyLoss()(outputs, b_labels)\n            total_train_loss += loss.item()\n\n            logits = outputs.detach().cpu().numpy()\n            label_ids = b_labels.cpu().numpy()\n            total_train_accuracy += flat_accuracy(logits, label_ids)\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        avg_train_loss = total_train_loss / len(train_dataloader)\n        avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n\n        # Validation\n        model.eval()\n        total_val_loss = 0\n        total_val_accuracy = 0\n        all_preds = []\n        all_labels = []\n\n        for batch in val_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n\n            # Move tensors to the same device\n            b_input_ids = b_input_ids.to(device)\n            b_input_mask = b_input_mask.to(device)\n            b_labels = b_labels.to(device)\n\n            with torch.no_grad():\n                outputs = model(b_input_ids, b_input_mask)\n                loss = nn.CrossEntropyLoss()(outputs, b_labels)\n                total_val_loss += loss.item()\n\n                logits = outputs.detach().cpu().numpy()\n                label_ids = b_labels.cpu().numpy()\n                total_val_accuracy += flat_accuracy(logits, label_ids)\n\n                all_preds.extend(np.argmax(logits, axis=1).flatten())\n                all_labels.extend(label_ids.flatten())\n\n        avg_val_loss = total_val_loss / len(val_dataloader)\n        avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n        elapsed_time = time.time() - start_time\n\n        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Train Accuracy: {avg_train_accuracy:.4f}\")\n        print(f\"Validation Loss: {avg_val_loss:.4f} | Validation Accuracy: {avg_val_accuracy:.4f}\")\n        print(f\"Time: {elapsed_time:.2f} seconds\")\n\n        # Save best model\n        if avg_val_accuracy > best_val_accuracy:\n            best_val_accuracy = avg_val_accuracy\n            best_model = model.state_dict()\n            best_params = params\n            torch.save(best_model, 'best_model.pth')\n            print(f\"New best model saved with accuracy: {best_val_accuracy:.4f}\")\n\n# Generate classification report\nprint(\"Classification Report:\")\nprint(classification_report(all_labels, all_preds))\n\n\n\n# Define search space for hyperparameters\nepochs = 5\nlearning_rates = [2e-5, 3e-5, 5e-5]\nbatch_sizes = [16, 32]\noptimizers = ['adamw', 'adam', 'rmsprop', 'sgd']\n\n# Number of random samples to try\nnum_samples = 5\n\n# Function to calculate accuracy\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n# Function to get optimizer\ndef get_optimizer(optimizer_name, model_parameters, lr):\n    if optimizer_name == 'adamw':\n        return optim.AdamW(model_parameters, lr=lr)\n    elif optimizer_name == 'adam':\n        return optim.Adam(model_parameters, lr=lr)\n    elif optimizer_name == 'rmsprop':\n        return optim.RMSprop(model_parameters, lr=lr)\n    elif optimizer_name == 'sgd':\n        return optim.SGD(model_parameters, lr=lr)\n\n# Randomly sample hyperparameter combinations\nrandom_hyperparams = [\n    {\n        \"optimizer\": random.choice(optimizers),\n        \"learning_rate\": random.choice(learning_rates),\n        \"batch_size\": random.choice(batch_sizes),\n    }\n    for _ in range(num_samples)\n]\n\nbest_accuracy = 0\nbest_params = {}\n\n# Iterate over randomly chosen hyperparameter sets\nfor params in random_hyperparams:\n    optimizer_name = params[\"optimizer\"]\n    lr = params[\"learning_rate\"]\n    batch_size = params[\"batch_size\"]\n\n    # Initialize data loaders\n    train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n    val_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=batch_size)\n\n    # Define optimizer and scheduler\n    optimizer = get_optimizer(optimizer_name, model.parameters(), lr)\n    total_steps = len(train_dataloader) * epochs\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n    # Move model to device\n    model.to(device)\n\n    for epoch in range(epochs):\n        start_time = time.time()\n\n        # Training\n        model.train()\n        total_train_loss = 0\n        total_train_accuracy = 0\n        for batch in train_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            b_input_ids, b_input_mask, b_labels = b_input_ids.to(device), b_input_mask.to(device), b_labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(b_input_ids, b_input_mask)\n            loss = nn.CrossEntropyLoss()(outputs, b_labels)\n            total_train_loss += loss.item()\n\n            logits = outputs.detach().cpu().numpy()\n            label_ids = b_labels.cpu().numpy()\n            total_train_accuracy += flat_accuracy(logits, label_ids)\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n        avg_train_loss = total_train_loss / len(train_dataloader)\n        avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n\n        # Validation\n        model.eval()\n        total_val_loss = 0\n        total_val_accuracy = 0\n        for batch in val_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            b_input_ids, b_input_mask, b_labels = b_input_ids.to(device), b_input_mask.to(device), b_labels.to(device)\n\n            with torch.no_grad():\n                outputs = model(b_input_ids, b_input_mask)\n                loss = nn.CrossEntropyLoss()(outputs, b_labels)\n                total_val_loss += loss.item()\n\n                logits = outputs.detach().cpu().numpy()\n                label_ids = b_labels.cpu().numpy()\n                total_val_accuracy += flat_accuracy(logits, label_ids)\n\n        avg_val_loss = total_val_loss / len(val_dataloader)\n        avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n\n        elapsed_time = time.time() - start_time\n\n        print(f\"Optimizer: {optimizer_name} | Learning Rate: {lr} | Batch Size: {batch_size}\")\n        print(f\"Epoch {epoch+1}\")\n        print(f\"Train Loss: {avg_train_loss:.4f} | Train Accuracy: {avg_train_accuracy:.4f}\")\n        print(f\"Validation Loss: {avg_val_loss:.4f} | Validation Accuracy: {avg_val_accuracy:.4f}\")\n        print(f\"Time: {elapsed_time:.2f} seconds\")\n        print(\"-\" * 50)\n\n        # Update best parameters if validation accuracy improves\n        if avg_val_accuracy > best_accuracy:\n            best_accuracy = avg_val_accuracy\n            best_params = {\"optimizer\": optimizer_name, \"learning_rate\": lr, \"batch_size\": batch_size}\n\nprint(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\nprint(f\"Best Parameters: Optimizer = {best_params['optimizer']}, Learning Rate = {best_params['learning_rate']}, Batch Size = {best_params['batch_size']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T06:46:53.011307Z","iopub.execute_input":"2026-02-15T06:46:53.011946Z","iopub.status.idle":"2026-02-15T09:22:28.161235Z","shell.execute_reply.started":"2026-02-15T06:46:53.011905Z","shell.execute_reply":"2026-02-15T09:22:28.160250Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.44.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.15.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.5)\nRequirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\nRequirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\nRequirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\nRequirement already satisfied: autoray==0.8.2 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.2)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\nRequirement already satisfied: pennylane-lightning>=0.44 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.44.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.5)\nRequirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (26.0rc2)\nRequirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\nRequirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning>=0.44->pennylane) (0.3.31.22.1)\nRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\nRequirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.1.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\nRequirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6383cd8db945e8a1334611defbbda2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a75d74a0884044ba900a7c5af8d766f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab4ed62a0ac14ddaa6a5984dbd9dcb7b"}},"metadata":{}},{"name":"stderr","text":"2026-02-15 06:47:03.291696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771138023.465173      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771138023.514330      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771138023.949009      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771138023.949051      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771138023.949054      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771138023.949057      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e5893dabb104d05b0f398a0150dcd3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b9c914b7e3f4e99b853f016425d8cb6"}},"metadata":{}},{"name":"stdout","text":"Testing configuration 1: {'learning_rate': 1e-05, 'epochs': 7, 'batch_size': 16}\nEpoch 1 | Train Loss: 0.6952 | Train Accuracy: 0.5089\nValidation Loss: 0.6922 | Validation Accuracy: 0.5512\nTime: 180.25 seconds\nNew best model saved with accuracy: 0.5512\nEpoch 2 | Train Loss: 0.6492 | Train Accuracy: 0.6190\nValidation Loss: 0.5176 | Validation Accuracy: 0.7630\nTime: 177.53 seconds\nNew best model saved with accuracy: 0.7630\nEpoch 3 | Train Loss: 0.4877 | Train Accuracy: 0.7800\nValidation Loss: 0.4699 | Validation Accuracy: 0.7866\nTime: 177.09 seconds\nNew best model saved with accuracy: 0.7866\nEpoch 4 | Train Loss: 0.4149 | Train Accuracy: 0.8173\nValidation Loss: 0.4670 | Validation Accuracy: 0.7915\nTime: 176.89 seconds\nNew best model saved with accuracy: 0.7915\nEpoch 5 | Train Loss: 0.3660 | Train Accuracy: 0.8473\nValidation Loss: 0.4487 | Validation Accuracy: 0.7877\nTime: 176.70 seconds\nEpoch 6 | Train Loss: 0.3359 | Train Accuracy: 0.8638\nValidation Loss: 0.4721 | Validation Accuracy: 0.7947\nTime: 176.88 seconds\nNew best model saved with accuracy: 0.7947\nEpoch 7 | Train Loss: 0.3175 | Train Accuracy: 0.8708\nValidation Loss: 0.4833 | Validation Accuracy: 0.7896\nTime: 176.75 seconds\nTesting configuration 2: {'learning_rate': 1e-05, 'epochs': 5, 'batch_size': 32}\nEpoch 1 | Train Loss: 0.3344 | Train Accuracy: 0.8638\nValidation Loss: 0.4596 | Validation Accuracy: 0.7868\nTime: 176.95 seconds\nEpoch 2 | Train Loss: 0.2851 | Train Accuracy: 0.8889\nValidation Loss: 0.4953 | Validation Accuracy: 0.7912\nTime: 177.18 seconds\nEpoch 3 | Train Loss: 0.2411 | Train Accuracy: 0.9131\nValidation Loss: 0.5400 | Validation Accuracy: 0.7896\nTime: 177.21 seconds\nEpoch 4 | Train Loss: 0.2005 | Train Accuracy: 0.9299\nValidation Loss: 0.5720 | Validation Accuracy: 0.7882\nTime: 176.72 seconds\nEpoch 5 | Train Loss: 0.1827 | Train Accuracy: 0.9372\nValidation Loss: 0.5904 | Validation Accuracy: 0.7849\nTime: 176.64 seconds\nTesting configuration 3: {'learning_rate': 1e-05, 'epochs': 3, 'batch_size': 16}\nEpoch 1 | Train Loss: 0.1970 | Train Accuracy: 0.9284\nValidation Loss: 0.6234 | Validation Accuracy: 0.7908\nTime: 176.50 seconds\nEpoch 2 | Train Loss: 0.1541 | Train Accuracy: 0.9473\nValidation Loss: 0.6166 | Validation Accuracy: 0.7819\nTime: 176.38 seconds\nEpoch 3 | Train Loss: 0.1299 | Train Accuracy: 0.9569\nValidation Loss: 0.6862 | Validation Accuracy: 0.7875\nTime: 176.56 seconds\nTesting configuration 4: {'learning_rate': 3e-05, 'epochs': 5, 'batch_size': 32}\nEpoch 1 | Train Loss: 0.2318 | Train Accuracy: 0.9120\nValidation Loss: 0.5574 | Validation Accuracy: 0.7922\nTime: 178.82 seconds\nEpoch 2 | Train Loss: 0.1632 | Train Accuracy: 0.9447\nValidation Loss: 0.6887 | Validation Accuracy: 0.7898\nTime: 177.80 seconds\nEpoch 3 | Train Loss: 0.1130 | Train Accuracy: 0.9630\nValidation Loss: 0.7099 | Validation Accuracy: 0.7938\nTime: 178.83 seconds\nEpoch 4 | Train Loss: 0.0785 | Train Accuracy: 0.9772\nValidation Loss: 0.7718 | Validation Accuracy: 0.7905\nTime: 178.46 seconds\nEpoch 5 | Train Loss: 0.0601 | Train Accuracy: 0.9846\nValidation Loss: 0.7778 | Validation Accuracy: 0.7931\nTime: 176.94 seconds\nTesting configuration 5: {'learning_rate': 5e-05, 'epochs': 7, 'batch_size': 16}\nEpoch 1 | Train Loss: 0.1872 | Train Accuracy: 0.9346\nValidation Loss: 0.5961 | Validation Accuracy: 0.7900\nTime: 177.13 seconds\nEpoch 2 | Train Loss: 0.1138 | Train Accuracy: 0.9636\nValidation Loss: 0.7079 | Validation Accuracy: 0.7922\nTime: 177.66 seconds\nEpoch 3 | Train Loss: 0.0790 | Train Accuracy: 0.9743\nValidation Loss: 0.7370 | Validation Accuracy: 0.7910\nTime: 177.89 seconds\nEpoch 4 | Train Loss: 0.0531 | Train Accuracy: 0.9840\nValidation Loss: 0.8635 | Validation Accuracy: 0.7980\nTime: 177.02 seconds\nNew best model saved with accuracy: 0.7980\nEpoch 5 | Train Loss: 0.0313 | Train Accuracy: 0.9911\nValidation Loss: 0.9118 | Validation Accuracy: 0.7887\nTime: 177.28 seconds\nEpoch 6 | Train Loss: 0.0196 | Train Accuracy: 0.9954\nValidation Loss: 1.0119 | Validation Accuracy: 0.7905\nTime: 177.44 seconds\nEpoch 7 | Train Loss: 0.0188 | Train Accuracy: 0.9958\nValidation Loss: 0.9880 | Validation Accuracy: 0.7915\nTime: 177.38 seconds\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.79      0.79      0.79      1073\n           1       0.79      0.79      0.79      1060\n\n    accuracy                           0.79      2133\n   macro avg       0.79      0.79      0.79      2133\nweighted avg       0.79      0.79      0.79      2133\n\nOptimizer: rmsprop | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 1\nTrain Loss: 0.6943 | Train Accuracy: 0.5142\nValidation Loss: 0.7110 | Validation Accuracy: 0.4975\nTime: 185.40 seconds\n--------------------------------------------------\nOptimizer: rmsprop | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 2\nTrain Loss: 0.6635 | Train Accuracy: 0.6022\nValidation Loss: 0.6454 | Validation Accuracy: 0.6613\nTime: 185.34 seconds\n--------------------------------------------------\nOptimizer: rmsprop | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 3\nTrain Loss: 0.5308 | Train Accuracy: 0.7501\nValidation Loss: 0.6051 | Validation Accuracy: 0.7162\nTime: 185.69 seconds\n--------------------------------------------------\nOptimizer: rmsprop | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 4\nTrain Loss: 0.4002 | Train Accuracy: 0.8263\nValidation Loss: 0.7266 | Validation Accuracy: 0.6868\nTime: 185.77 seconds\n--------------------------------------------------\nOptimizer: rmsprop | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 5\nTrain Loss: 0.2970 | Train Accuracy: 0.8821\nValidation Loss: 0.5596 | Validation Accuracy: 0.7624\nTime: 186.08 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 1\nTrain Loss: 0.5995 | Train Accuracy: 0.6574\nValidation Loss: 0.7103 | Validation Accuracy: 0.4896\nTime: 190.63 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 2\nTrain Loss: 0.6320 | Train Accuracy: 0.6325\nValidation Loss: 0.6851 | Validation Accuracy: 0.4975\nTime: 190.41 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 3\nTrain Loss: 0.6776 | Train Accuracy: 0.5236\nValidation Loss: 0.6776 | Validation Accuracy: 0.4975\nTime: 190.58 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 4\nTrain Loss: 0.6721 | Train Accuracy: 0.5301\nValidation Loss: 0.6717 | Validation Accuracy: 0.5427\nTime: 190.02 seconds\n--------------------------------------------------\nOptimizer: adam | Learning Rate: 5e-05 | Batch Size: 16\nEpoch 5\nTrain Loss: 0.6544 | Train Accuracy: 0.5624\nValidation Loss: 0.6451 | Validation Accuracy: 0.6197\nTime: 189.56 seconds\n--------------------------------------------------\nOptimizer: sgd | Learning Rate: 5e-05 | Batch Size: 32\nEpoch 1\nTrain Loss: 0.6211 | Train Accuracy: 0.6201\nValidation Loss: 0.6450 | Validation Accuracy: 0.6191\nTime: 171.20 seconds\n--------------------------------------------------\nOptimizer: sgd | Learning Rate: 5e-05 | Batch Size: 32\nEpoch 2\nTrain Loss: 0.6167 | Train Accuracy: 0.6241\nValidation Loss: 0.6446 | Validation Accuracy: 0.6191\nTime: 171.19 seconds\n--------------------------------------------------\nOptimizer: sgd | Learning Rate: 5e-05 | Batch Size: 32\nEpoch 3\nTrain Loss: 0.6070 | Train Accuracy: 0.6496\nValidation Loss: 0.6439 | Validation Accuracy: 0.6503\nTime: 170.83 seconds\n--------------------------------------------------\nOptimizer: sgd | Learning Rate: 5e-05 | Batch Size: 32\nEpoch 4\nTrain Loss: 0.6028 | Train Accuracy: 0.6612\nValidation Loss: 0.6476 | Validation Accuracy: 0.6541\nTime: 171.76 seconds\n--------------------------------------------------\nOptimizer: sgd | Learning Rate: 5e-05 | Batch Size: 32\nEpoch 5\nTrain Loss: 0.6005 | Train Accuracy: 0.6642\nValidation Loss: 0.6437 | Validation Accuracy: 0.6527\nTime: 171.27 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 1\nTrain Loss: 0.5385 | Train Accuracy: 0.7328\nValidation Loss: 0.6119 | Validation Accuracy: 0.7327\nTime: 177.61 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 2\nTrain Loss: 0.3971 | Train Accuracy: 0.8383\nValidation Loss: 0.5462 | Validation Accuracy: 0.7066\nTime: 178.04 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 3\nTrain Loss: 0.3047 | Train Accuracy: 0.8793\nValidation Loss: 0.5777 | Validation Accuracy: 0.7651\nTime: 177.67 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 4\nTrain Loss: 0.2413 | Train Accuracy: 0.9088\nValidation Loss: 0.5710 | Validation Accuracy: 0.7607\nTime: 177.55 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 5\nTrain Loss: 0.2009 | Train Accuracy: 0.9283\nValidation Loss: 0.6271 | Validation Accuracy: 0.7807\nTime: 177.63 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 1\nTrain Loss: 0.2148 | Train Accuracy: 0.9221\nValidation Loss: 0.6162 | Validation Accuracy: 0.7721\nTime: 177.60 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 2\nTrain Loss: 0.1418 | Train Accuracy: 0.9504\nValidation Loss: 0.7477 | Validation Accuracy: 0.7623\nTime: 178.69 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 3\nTrain Loss: 0.0968 | Train Accuracy: 0.9689\nValidation Loss: 0.8289 | Validation Accuracy: 0.7756\nTime: 177.58 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 4\nTrain Loss: 0.0693 | Train Accuracy: 0.9801\nValidation Loss: 0.8982 | Validation Accuracy: 0.7789\nTime: 178.09 seconds\n--------------------------------------------------\nOptimizer: adamw | Learning Rate: 3e-05 | Batch Size: 32\nEpoch 5\nTrain Loss: 0.0546 | Train Accuracy: 0.9864\nValidation Loss: 0.9367 | Validation Accuracy: 0.7733\nTime: 178.02 seconds\n--------------------------------------------------\nBest Validation Accuracy: 0.7807\nBest Parameters: Optimizer = adamw, Learning Rate = 3e-05, Batch Size = 32\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, confusion_matrix,\n    classification_report, roc_curve\n)\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\ndef evaluate_binary_model(model, dataloader, device):\n    model.eval()\n    all_true_labels = []\n    all_probs = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            b_input_ids = b_input_ids.to(device)\n            b_input_mask = b_input_mask.to(device)\n            b_labels = b_labels.to(device)\n\n            outputs = model(b_input_ids, b_input_mask)\n            probs = torch.softmax(outputs, dim=1)\n\n            all_true_labels.append(b_labels.cpu().numpy())\n            all_probs.append(probs.cpu().numpy())\n\n    # Convert to numpy\n    all_true_labels = np.concatenate(all_true_labels)\n    all_probs = np.concatenate(all_probs)\n    all_preds = np.argmax(all_probs, axis=1)\n\n    # ================= Metrics =================\n    tn, fp, fn, tp = confusion_matrix(all_true_labels, all_preds).ravel()\n\n    accuracy = accuracy_score(all_true_labels, all_preds)\n    precision = precision_score(all_true_labels, all_preds)\n    recall = recall_score(all_true_labels, all_preds)          # Sensitivity\n    specificity = tn / (tn + fp)\n    f1 = f1_score(all_true_labels, all_preds)\n    auc = roc_auc_score(all_true_labels, all_probs[:, 1])\n\n    # ================= Print metrics =================\n    print(\"===== Evaluation Metrics =====\")\n    print(f\"Accuracy     : {accuracy:.4f}\")\n    print(f\"Precision    : {precision:.4f}\")\n    print(f\"Recall       : {recall:.4f}\")\n    print(f\"Sensitivity : {recall:.4f}\")\n    print(f\"Specificity : {specificity:.4f}\")\n    print(f\"F1-score    : {f1:.4f}\")\n    print(f\"AUC         : {auc:.4f}\")\n\n    # ================= Classification Report =================\n    print(\"\\n===== Classification Report =====\")\n    print(classification_report(all_true_labels, all_preds, digits=4))\n\n    # ================= ROC Curve (Both Classes) =================\n    fpr_0, tpr_0, _ = roc_curve(all_true_labels, all_probs[:, 0], pos_label=0)\n    fpr_1, tpr_1, _ = roc_curve(all_true_labels, all_probs[:, 1], pos_label=1)\n\n    auc_0 = roc_auc_score(1 - all_true_labels, all_probs[:, 0])\n    auc_1 = roc_auc_score(all_true_labels, all_probs[:, 1])\n\n    plt.figure(figsize=(7, 6))\n    plt.plot(fpr_0, tpr_0, label=f\"Class 0 ROC (AUC = {auc_0:.2f})\", lw=2)\n    plt.plot(fpr_1, tpr_1, label=f\"Class 1 ROC (AUC = {auc_1:.2f})\", lw=2)\n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve for Binary Classification\")\n    plt.legend(loc=\"lower right\")\n    plt.grid()\n    plt.tight_layout()\n    plt.show()\n\n    return accuracy, precision, recall, specificity, f1, auc\n\n\naccuracy, precision, recall, specificity, f1, auc = evaluate_binary_model(\n    model, val_dataloader, device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T09:22:28.162834Z","iopub.execute_input":"2026-02-15T09:22:28.163581Z","iopub.status.idle":"2026-02-15T09:22:45.585618Z","shell.execute_reply.started":"2026-02-15T09:22:28.163556Z","shell.execute_reply":"2026-02-15T09:22:45.585069Z"}},"outputs":[{"name":"stdout","text":"===== Evaluation Metrics =====\nAccuracy     : 0.7731\nPrecision    : 0.7812\nRecall       : 0.7547\nSensitivity : 0.7547\nSpecificity : 0.7912\nF1-score    : 0.7678\nAUC         : 0.8334\n\n===== Classification Report =====\n              precision    recall  f1-score   support\n\n           0     0.7656    0.7912    0.7782      1073\n           1     0.7812    0.7547    0.7678      1060\n\n    accuracy                         0.7731      2133\n   macro avg     0.7734    0.7730    0.7730      2133\nweighted avg     0.7734    0.7731    0.7730      2133\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 700x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =====================================\n# 1. Imports\n# =====================================\nimport re, warnings\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport pennylane as qml\n\nfrom torch.optim import AdamW\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, confusion_matrix\n)\n\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nfrom datasets import load_dataset\nimport nltk\nfrom nltk.corpus import stopwords\n\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# =====================================\n# 2. Load Dataset (Binary Sentiment)\n# =====================================\nds = load_dataset(\"mattymchen/mr\")\n# Convert train split to pandas (MPQA already split)\ndf = ds[\"test\"].to_pandas()\n\nprint(\"Dataset shape:\", df.shape)\n\n# =====================================\n# 3. Preprocessing\n# =====================================\n# ===============================\n# Dataset Preprocessing\n# ===============================\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n    text = re.sub(r\"\\d+\", \"\", text)\n    words = [w for w in text.split() if w not in stop_words]\n    return \" \".join(words)\n\ndf[\"cleaned_text\"] = df[\"text\"].astype(str).apply(clean_text)\n\nle = LabelEncoder()\ndf[\"label\"] = le.fit_transform(df[\"label\"])\nmin_class = df[\"label\"].value_counts().min()\n\n# Balance classes\ndf = (\n    df.groupby(\"label\", group_keys=False)\n      .apply(lambda x: x.sample(min_class, random_state=42))\n      .sample(frac=1, random_state=42)\n)\n\n# =====================================\n# 4. Tokenization\n# =====================================\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n\ntokens = tokenizer(\n    df[\"cleaned_text\"].tolist(),\n    padding=\"max_length\",\n    truncation=True,\n    max_length=128,\n    return_tensors=\"pt\"\n)\n\ninput_ids = tokens[\"input_ids\"]\nattention_mask = tokens[\"attention_mask\"]\nlabels = torch.tensor(df[\"label\"].values)\n\nX_train, X_val, y_train, y_val, m_train, m_val = train_test_split(\n    input_ids, labels, attention_mask,\n    test_size=0.2, random_state=42\n)\n\ntrain_data = TensorDataset(X_train, m_train, y_train)\nval_data   = TensorDataset(X_val, m_val, y_val)\n\n# =====================================\n# 5. Quantum Circuits\n# =====================================\ndev = qml.device(\"default.qubit\", wires=2)\n\n@qml.qnode(dev, interface=\"torch\")\ndef qc1(weights, x):\n    qml.Hadamard(0)\n    qml.Hadamard(1)\n    qml.RX(x[0], 0)\n    qml.RY(x[1], 1)\n    qml.CNOT([0, 1])\n    qml.RZ(weights[0], 0)\n    qml.RZ(weights[1], 1)\n    return qml.expval(qml.PauliZ(0))\n\n@qml.qnode(dev, interface=\"torch\")\ndef qc2(weights, x):\n    qml.Hadamard(0)\n    qml.RY(x[0], 0)\n    qml.RX(x[1], 1)\n    qml.CNOT([1, 0])\n    qml.RX(weights[0], 0)\n    qml.RY(weights[1], 1)\n    return qml.expval(qml.PauliZ(0))\n\n@qml.qnode(dev, interface=\"torch\")\ndef qc3(weights, x):\n    for i in range(2):\n        qml.Hadamard(i)\n        qml.RX(x[i], i)\n        qml.RY(weights[i], i)\n        qml.RZ(weights[i], i)\n    qml.CNOT([0, 1])\n    return qml.expval(qml.PauliZ(1))\n\n@qml.qnode(dev, interface=\"torch\")\ndef qc4(weights, x):\n    qml.Hadamard(0)\n    qml.CNOT([0, 1])\n    qml.RX(x[0], 0)\n    qml.RY(x[1], 1)\n    qml.CNOT([1, 0])\n    qml.RZ(weights[0], 0)\n    qml.RZ(weights[1], 1)\n    return qml.expval(qml.PauliZ(0))\n\nQUANTUM_CIRCUITS = {\n    \"QC1\": qc1,\n    \"QC2\": qc2,\n    \"QC3\": qc3,\n    \"QC4\": qc4\n}\n\n# =====================================\n# 6. QBiLSTM Model\n# =====================================\nclass QBiLSTM(nn.Module):\n    def __init__(self, quantum_circuit):\n        super().__init__()\n\n        self.qc = quantum_circuit\n        self.q_weights = nn.Parameter(torch.randn(2))\n\n        self.encoder = AutoModel.from_pretrained(\"microsoft/deberta-v3-base\")\n\n        self.bilstm = nn.LSTM(\n            input_size=768,\n            hidden_size=128,\n            bidirectional=True,\n            batch_first=True\n        )\n\n        self.fc = nn.Linear(257, 2)\n\n    def quantum_layer(self, x):\n        q_out = [self.qc(self.q_weights, v[:2]) for v in x]\n        q_out = torch.stack(q_out)\n        q_out = q_out.float()\n        return q_out.unsqueeze(1)\n\n    def forward(self, input_ids, attention_mask):\n        enc = self.encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        ).last_hidden_state\n\n        lstm_out, _ = self.bilstm(enc)\n        h = lstm_out[:, -1, :]\n\n        q_feat = self.quantum_layer(h)\n        h = torch.cat([h, q_feat], dim=1)\n\n        return self.fc(h)\n\n# =====================================\n# 7. Training + Evaluation\n# =====================================\ndef train_and_validate(model, params):\n\n    train_loader = DataLoader(train_data, batch_size=params[\"batch_size\"], shuffle=True)\n    val_loader   = DataLoader(val_data, batch_size=params[\"batch_size\"])\n\n    optimizer = AdamW(model.parameters(), lr=params[\"learning_rate\"])\n    loss_fn = nn.CrossEntropyLoss()\n\n    total_steps = len(train_loader) * params[\"epochs\"]\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, 0, total_steps\n    )\n\n    # Training\n    for _ in range(params[\"epochs\"]):\n        model.train()\n        for ids, mask, y in train_loader:\n            ids, mask, y = ids.to(device), mask.to(device), y.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(ids, mask)\n            loss = loss_fn(outputs, y)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n    # Evaluation\n    model.eval()\n    preds, gold, probs = [], [], []\n\n    with torch.no_grad():\n        for ids, mask, y in val_loader:\n            ids, mask = ids.to(device), mask.to(device)\n            logits = model(ids, mask)\n\n            softmax = torch.softmax(logits, dim=1)\n            preds.extend(torch.argmax(logits, 1).cpu().numpy())\n            probs.extend(softmax[:,1].cpu().numpy())\n            gold.extend(y.numpy())\n\n    acc = accuracy_score(gold, preds)\n    prec = precision_score(gold, preds)\n    recall = recall_score(gold, preds)\n    f1 = f1_score(gold, preds)\n    auc = roc_auc_score(gold, probs)\n\n    tn, fp, fn, tp = confusion_matrix(gold, preds).ravel()\n    specificity = tn / (tn + fp)\n\n    return acc, prec, recall, specificity, f1, auc\n\n# =====================================\n# 8. Run All 4 Models\n# =====================================\nparams = {\n    \"learning_rate\": 2e-5,\n    \"batch_size\": 16,\n    \"epochs\": 5\n}\n\nfinal_results = {}\n\nfor name, qc in QUANTUM_CIRCUITS.items():\n    print(f\"\\n===== Training {name} =====\")\n\n    model = QBiLSTM(qc).to(device)\n    metrics = train_and_validate(model, params)\n\n    final_results[name] = metrics\n\n# =====================================\n# 9. Final Comparison\n# =====================================\nprint(\"\\n===== FINAL RESULTS =====\")\nprint(\"Model | Accuracy | Precision | Sensitivity | Specificity | F1 | AUC\")\n\nfor k, v in final_results.items():\n    print(f\"{k} | {v[0]:.4f} | {v[1]:.4f} | {v[2]:.4f} | {v[3]:.4f} | {v[4]:.4f} | {v[5]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T04:22:42.587239Z","iopub.execute_input":"2026-02-16T04:22:42.587619Z","iopub.status.idle":"2026-02-16T05:30:01.679825Z","shell.execute_reply.started":"2026-02-16T04:22:42.587590Z","shell.execute_reply":"2026-02-16T05:30:01.679133Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"Dataset shape: (10662, 2)\n\n===== Training QC1 =====\n\n===== Training QC2 =====\n\n===== Training QC3 =====\n\n===== Training QC4 =====\n\n===== FINAL RESULTS =====\nModel | Accuracy | Precision | Sensitivity | Specificity | F1 | AUC\nQC1 | 0.8594 | 0.8523 | 0.8589 | 0.8597 | 0.8556 | 0.9271\nQC2 | 0.8486 | 0.8483 | 0.8377 | 0.8588 | 0.8430 | 0.9177\nQC3 | 0.8514 | 0.8485 | 0.8444 | 0.8579 | 0.8465 | 0.9255\nQC4 | 0.8444 | 0.8484 | 0.8271 | 0.8607 | 0.8376 | 0.8972\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import random\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nfrom torch import optim\n\nepochs = 5\nlearning_rates = [2e-5, 3e-5, 5e-5]\nbatch_sizes = [16, 32]\noptimizers = ['adamw', 'adam', 'rmsprop', 'sgd']\nnum_samples = 5\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\ndef get_optimizer(optimizer_name, model_parameters, lr):\n    if optimizer_name == 'adamw':\n        return optim.AdamW(model_parameters, lr=lr)\n    elif optimizer_name == 'adam':\n        return optim.Adam(model_parameters, lr=lr)\n    elif optimizer_name == 'rmsprop':\n        return optim.RMSprop(model_parameters, lr=lr)\n    elif optimizer_name == 'sgd':\n        return optim.SGD(model_parameters, lr=lr)\nfinal_results = {}\n\nfor qc_name, qc in QUANTUM_CIRCUITS.items():\n    print(f\"\\n==============================\")\n    print(f\" Quantum Circuit: {qc_name}\")\n    print(f\"==============================\")\n\n    best_accuracy = 0\n    best_params = None\n\n    # Random hyperparameter sampling\n    random_hyperparams = [\n        {\n            \"optimizer\": random.choice(optimizers),\n            \"learning_rate\": random.choice(learning_rates),\n            \"batch_size\": random.choice(batch_sizes),\n        }\n        for _ in range(num_samples)\n    ]\n\n    for params in random_hyperparams:\n        optimizer_name = params[\"optimizer\"]\n        lr = params[\"learning_rate\"]\n        batch_size = params[\"batch_size\"]\n\n        print(f\"\\n Testing {params}\")\n\n        # Fresh model for each trial (VERY IMPORTANT)\n        model = QBiLSTM(qc).to(device)\n\n        train_dataloader = DataLoader(\n            train_data,\n            sampler=RandomSampler(train_data),\n            batch_size=batch_size\n        )\n\n        val_dataloader = DataLoader(\n            val_data,\n            sampler=SequentialSampler(val_data),\n            batch_size=batch_size\n        )\n\n        optimizer = get_optimizer(optimizer_name, model.parameters(), lr)\n        loss_fn = nn.CrossEntropyLoss()\n\n        total_steps = len(train_dataloader) * epochs\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0,\n            num_training_steps=total_steps\n        )\n\n        # ===== Training =====\n        for epoch in range(epochs):\n            model.train()\n            total_train_loss = 0\n            total_train_accuracy = 0\n\n            for batch in train_dataloader:\n                b_input_ids, b_input_mask, b_labels = batch\n                b_input_ids = b_input_ids.to(device)\n                b_input_mask = b_input_mask.to(device)\n                b_labels = b_labels.to(device)\n\n                optimizer.zero_grad()\n                outputs = model(b_input_ids, b_input_mask)\n                loss = loss_fn(outputs, b_labels)\n\n                total_train_loss += loss.item()\n                logits = outputs.detach().cpu().numpy()\n                total_train_accuracy += flat_accuracy(logits, b_labels.cpu().numpy())\n\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n\n            avg_train_loss = total_train_loss / len(train_dataloader)\n            avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n\n            # ===== Validation =====\n            model.eval()\n            total_val_accuracy = 0\n            total_val_loss = 0\n\n            with torch.no_grad():\n                for batch in val_dataloader:\n                    b_input_ids, b_input_mask, b_labels = batch\n                    b_input_ids = b_input_ids.to(device)\n                    b_input_mask = b_input_mask.to(device)\n                    b_labels = b_labels.to(device)\n\n                    outputs = model(b_input_ids, b_input_mask)\n                    loss = loss_fn(outputs, b_labels)\n\n                    total_val_loss += loss.item()\n                    logits = outputs.detach().cpu().numpy()\n                    total_val_accuracy += flat_accuracy(logits, b_labels.cpu().numpy())\n\n            avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n\n            print(\n                f\"Epoch {epoch+1} | \"\n                f\"Train Acc: {avg_train_accuracy:.4f} | \"\n                f\"Val Acc: {avg_val_accuracy:.4f}\"\n            )\n\n        # ===== Track best =====\n        if avg_val_accuracy > best_accuracy:\n            best_accuracy = avg_val_accuracy\n            best_params = {\n                \"optimizer\": optimizer_name,\n                \"learning_rate\": lr,\n                \"batch_size\": batch_size\n            }\n\n    final_results[qc_name] = {\n        \"best_accuracy\": best_accuracy,\n        \"best_params\": best_params\n    }\n\n    print(f\"\\n BEST for {qc_name}: {best_accuracy:.4f}\")\n    print(f\" PARAMS: {best_params}\")\n\nprint(\"\\n===== FINAL QUANTUM CIRCUIT COMPARISON =====\")\nfor qc, res in final_results.items():\n    print(\n        f\"{qc} | Accuracy: {res['best_accuracy']:.4f} | \"\n        f\"Params: {res['best_params']}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:35:12.063323Z","iopub.execute_input":"2026-02-16T05:35:12.063902Z","iopub.status.idle":"2026-02-16T06:36:00.236678Z","shell.execute_reply.started":"2026-02-16T05:35:12.063877Z","shell.execute_reply":"2026-02-16T06:36:00.235516Z"}},"outputs":[{"name":"stdout","text":"\n==============================\n Quantum Circuit: QC1\n==============================\n\n Testing {'optimizer': 'adam', 'learning_rate': 5e-05, 'batch_size': 32}\nEpoch 1 | Train Acc: 0.5275 | Val Acc: 0.6574\nEpoch 2 | Train Acc: 0.5700 | Val Acc: 0.6531\nEpoch 3 | Train Acc: 0.5130 | Val Acc: 0.4854\nEpoch 4 | Train Acc: 0.5017 | Val Acc: 0.5146\nEpoch 5 | Train Acc: 0.5025 | Val Acc: 0.4854\n\n Testing {'optimizer': 'adam', 'learning_rate': 3e-05, 'batch_size': 16}\nEpoch 1 | Train Acc: 0.5160 | Val Acc: 0.5132\nEpoch 2 | Train Acc: 0.5144 | Val Acc: 0.5132\nEpoch 3 | Train Acc: 0.5499 | Val Acc: 0.5160\nEpoch 4 | Train Acc: 0.6007 | Val Acc: 0.6991\nEpoch 5 | Train Acc: 0.7756 | Val Acc: 0.7690\n\n Testing {'optimizer': 'adamw', 'learning_rate': 3e-05, 'batch_size': 32}\nEpoch 1 | Train Acc: 0.6256 | Val Acc: 0.7572\nEpoch 2 | Train Acc: 0.7976 | Val Acc: 0.8391\nEpoch 3 | Train Acc: 0.8671 | Val Acc: 0.8435\nEpoch 4 | Train Acc: 0.9059 | Val Acc: 0.8412\nEpoch 5 | Train Acc: 0.9398 | Val Acc: 0.8512\n\n Testing {'optimizer': 'adamw', 'learning_rate': 3e-05, 'batch_size': 16}\nEpoch 1 | Train Acc: 0.5317 | Val Acc: 0.6021\nEpoch 2 | Train Acc: 0.5289 | Val Acc: 0.5781\nEpoch 3 | Train Acc: 0.7271 | Val Acc: 0.8115\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3585302195.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_input_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/3781048881.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mq_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/3781048881.py\u001b[0m in \u001b[0;36mquantum_layer\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquantum_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mq_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mq_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mq_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcapture_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m_impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_program\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_classical_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m         res = execute(\n\u001b[0m\u001b[1;32m    837\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/execution.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mouter_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_informative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"should only contain device preprocessing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0muser_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    296\u001b[0m     )\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mno_interface_boundary_required\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/workflow/run.py\u001b[0m in \u001b[0;36minner_execute\u001b[0;34m(tapes)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransformed_tapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_tapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/modifiers/simulator_tracking.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExecutionConfig\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntracked_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuantumScript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/modifiers/single_tape_support.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mis_single_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mcircuits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_single_circuit\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/logging/decorators.py\u001b[0m in \u001b[0;36mwrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0m_debug_log_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             return tuple(\n\u001b[0m\u001b[1;32m    825\u001b[0m                 _simulate_wrapper(\n\u001b[1;32m    826\u001b[0m                     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             return tuple(\n\u001b[0;32m--> 825\u001b[0;31m                 _simulate_wrapper(\n\u001b[0m\u001b[1;32m    826\u001b[0m                     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     {\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_simulate_wrapper\u001b[0;34m(circuit, kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_simulate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/logging/decorators.py\u001b[0m in \u001b[0;36mwrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0m_debug_log_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/qubit/simulate.py\u001b[0m in \u001b[0;36msimulate\u001b[0;34m(circuit, debugger, state_cache, **execution_kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0mops_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeas_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax_random_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprng_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     state, is_state_batched = get_final_state(\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebugger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprng_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mops_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexecution_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/logging/decorators.py\u001b[0m in \u001b[0;36mwrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0m_debug_log_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/qubit/simulate.py\u001b[0m in \u001b[0;36mget_final_state\u001b[0;34m(circuit, debugger, **execution_kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMidMeasure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mprng_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax_random_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprng_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         state = apply_operation(\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    910\u001b[0m                             '1 positional argument')\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/qubit/apply_operation.py\u001b[0m in \u001b[0;36mapply_operation\u001b[0;34m(op, state, is_state_batched, debugger, **_)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \"\"\"\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_operation_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_state_batched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/qubit/apply_operation.py\u001b[0m in \u001b[0;36m_apply_operation_default\u001b[0;34m(op, state, is_state_batched, debugger)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mEINSUM_STATE_WIRECOUNT_PERF_THRESHOLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     ) or (op.batch_size and is_state_batched):\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_operation_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_state_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_state_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_operation_tensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_state_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_state_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/qubit/apply_operation.py\u001b[0m in \u001b[0;36mapply_operation_einsum\u001b[0;34m(op, state, is_state_batched)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mreshaped_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mat_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meinsum_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/math/multi_dispatch.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(indices, like, optimize, *operands)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlike\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# torch einsum doesn't support the optimize keyword argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlike\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover (TensorFlow tests were disabled during deprecation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;31m# Unpacking and casting necessary for higher order derivatives,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autoray/autoray.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_choose_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lib_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    roc_auc_score,\n    roc_curve,\n    confusion_matrix\n)\nfrom sklearn.preprocessing import label_binarize\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n# ----- Evaluation function -----\ndef evaluate_model(model, dataloader, num_classes):\n    model.eval()\n\n    all_logits = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            b_input_ids = b_input_ids.to(device)\n            b_input_mask = b_input_mask.to(device)\n\n            outputs = model(b_input_ids, b_input_mask)\n\n            all_logits.append(outputs.cpu())\n            all_labels.append(b_labels)\n\n    logits = torch.cat(all_logits).numpy()\n    labels = torch.cat(all_labels).numpy()\n\n    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()\n    preds = np.argmax(probs, axis=1)\n\n    # ---- Metrics ----\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, average=\"macro\")\n    sensitivity = recall_score(labels, preds, average=\"macro\")  # Recall\n    f1 = f1_score(labels, preds, average=\"macro\")\n\n    # ---- Specificity ----\n    cm = confusion_matrix(labels, preds)\n    specificity_per_class = []\n    for i in range(num_classes):\n        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n        fp = cm[:, i].sum() - cm[i, i]\n        specificity_per_class.append(tn / (tn + fp + 1e-9))\n    specificity = np.mean(specificity_per_class)\n\n    # ---- AUC ----\n    if num_classes == 2:\n        auc = roc_auc_score(labels, probs[:, 1])  # binary case\n    else:\n        labels_bin = label_binarize(labels, classes=list(range(num_classes)))\n        auc = roc_auc_score(labels_bin, probs, average=\"macro\", multi_class=\"ovr\")\n\n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"sensitivity\": sensitivity,\n        \"specificity\": specificity,\n        \"f1\": f1,\n        \"auc\": auc,\n        \"labels\": labels,\n        \"probs\": probs\n    }\n\n# ----- Number of classes -----\nnum_classes = len(torch.unique(train_data.tensors[2]))  # or 2 for binary\n\nbest_models_results = {}\n\n# ----- Evaluate each best model -----\nfor qc_name, res in final_results.items():\n    print(f\"\\nEvaluating BEST model for {qc_name}\")\n\n    params = res[\"best_params\"]\n\n    # Fresh model\n    model = QBiLSTM(QUANTUM_CIRCUITS[qc_name]).to(device)\n\n    train_loader = DataLoader(\n        train_data,\n        sampler=RandomSampler(train_data),\n        batch_size=params[\"batch_size\"]\n    )\n\n    val_loader = DataLoader(\n        val_data,\n        sampler=SequentialSampler(val_data),\n        batch_size=params[\"batch_size\"]\n    )\n\n    optimizer = get_optimizer(params[\"optimizer\"], model.parameters(), params[\"learning_rate\"])\n    loss_fn = nn.CrossEntropyLoss()\n\n    # ---- Retrain ----\n    for epoch in range(epochs):\n        model.train()\n        for batch in train_loader:\n            b_input_ids, b_input_mask, b_labels = batch\n            b_input_ids, b_input_mask, b_labels = b_input_ids.to(device), b_input_mask.to(device), b_labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(b_input_ids, b_input_mask)\n            loss = loss_fn(outputs, b_labels)\n            loss.backward()\n            optimizer.step()\n\n    # ---- Final Evaluation ----\n    metrics = evaluate_model(model, val_loader, num_classes)\n    best_models_results[qc_name] = metrics\n\n# ----- Print Summary Table -----\nprint(\"\\n===== FINAL PERFORMANCE COMPARISON =====\")\nprint(\"Model | Accuracy | Precision | Sensitivity | Specificity | F1 | AUC\")\nprint(\"-\"*75)\nfor qc, m in best_models_results.items():\n    print(f\"{qc} | {m['accuracy']:.4f} | {m['precision']:.4f} | {m['sensitivity']:.4f} | {m['specificity']:.4f} | {m['f1']:.4f} | {m['auc']:.4f}\")\n\n# ----- Plot ROC Curves -----\nfor qc, m in best_models_results.items():\n    labels = m[\"labels\"]\n    probs = m[\"probs\"]\n\n    plt.figure(figsize=(7,6))\n    if num_classes == 2:\n        fpr, tpr, _ = roc_curve(labels, probs[:,1])\n        auc_score = roc_auc_score(labels, probs[:,1])\n        plt.plot(fpr, tpr, label=f\"AUC={auc_score:.3f}\")\n    else:\n        labels_bin = label_binarize(labels, classes=list(range(num_classes)))\n        for i in range(num_classes):\n            fpr, tpr, _ = roc_curve(labels_bin[:, i], probs[:, i])\n            auc_i = roc_auc_score(labels_bin[:, i], probs[:, i])\n            plt.plot(fpr, tpr, label=f\"Class {i} (AUC={auc_i:.3f})\")\n\n    plt.plot([0,1], [0,1], linestyle=\"--\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(f\"ROC Curve â€“ {qc}\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-14T07:49:53.065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}